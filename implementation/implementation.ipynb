{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "first of we start with preprocessing the raw data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "            user_id  recipe_id  rating\n0             38094      40893       4\n1           1293707      40893       5\n2              8937      44394       4\n3            126440      85009       5\n4             57222      85009       5\n...             ...        ...     ...\n1132362      116593      72730       0\n1132363      583662     386618       5\n1132364      157126      78003       5\n1132365       53932      78003       4\n1132366  2001868099      78003       5\n\n[1132367 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>recipe_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>38094</td>\n      <td>40893</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1293707</td>\n      <td>40893</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8937</td>\n      <td>44394</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126440</td>\n      <td>85009</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57222</td>\n      <td>85009</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1132362</th>\n      <td>116593</td>\n      <td>72730</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1132363</th>\n      <td>583662</td>\n      <td>386618</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1132364</th>\n      <td>157126</td>\n      <td>78003</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1132365</th>\n      <td>53932</td>\n      <td>78003</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1132366</th>\n      <td>2001868099</td>\n      <td>78003</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>1132367 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/RAW_interactions.csv')\n",
    "df.drop('review', axis=1, inplace=True)\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "df.reset_index()\n",
    "df.drop_duplicates(subset=['user_id', 'recipe_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#Set all ratings to 1 (even negative interactions are seen as interactions)\n",
    "# df.loc[:,'rating'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#randomly drop a subset of data as we dont have enough resource to run the entire dataset\n",
    "# unique_recipes = df.recipe_id.unique()\n",
    "# subset = np.random.choice(unique_recipes, size=int(len(unique_recipes) / 10), replace=False, p=None)\n",
    "# # Keep only the recipes that were in the randomly sampled df\n",
    "# df = df[df['recipe_id'].isin(subset)]\n",
    "# df.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "#Preprocessing step where we remove all recipes that only have a single review from a person that only has a single review\n",
    "#This is done as these items will never be connected to other items and thus will never be recommended\n",
    "#\n",
    "# df['counts'] = df.groupby(['recipe_id'])['recipe_id'].transform('size')\n",
    "# df['counts_user'] = df.groupby(['user_id'])['user_id'].transform('size')\n",
    "# # 1121916 interaction in df after the and drop\n",
    "# # df = df.drop(df[(df['counts'] == 1) & (df['counts_user'] == 1)].index)\n",
    "#\n",
    "# # 884607 interactions after the or drop\n",
    "# df = df.drop(df[(df['counts'] == 1) | (df['counts_user'] == 1)].index)\n",
    "# df.drop(['counts', 'counts_user'], axis=1, inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "g1 = df.groupby('recipe_id', as_index=False)['user_id'].size()\n",
    "g1 = g1.rename({'size': 'count_item'}, axis='columns')\n",
    "g2 = df.groupby('user_id', as_index=False)['recipe_id'].size()\n",
    "g2 = g2.rename({'size': 'count_user'}, axis='columns')\n",
    "df = pd.merge(df, g1, how='left', on=['recipe_id'])\n",
    "df = pd.merge(df, g2, how='left', on=['user_id'])\n",
    "df = df[df['count_item'] >= 15]\n",
    "df = df[df['count_user'] >= 15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The recipes and users don't go from 0 to amount so if we were to put this in a matrix we would get empty columns and rows. This is not that handy so we reindex both the user_id and recipe_ids\n",
    "\n",
    "This is a step we must not forget when entering the data in the model, as we also need to remap our input data using the same remapping that was used here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "userSet = set(df['user_id'].to_list())\n",
    "user_transform_dict = dict(map(reversed, enumerate(userSet)))\n",
    "recipeSet = set(df['recipe_id'].to_list())\n",
    "recipe_transform_dict = dict(map(reversed, enumerate(recipeSet)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "keep_nan = [k for k, v in user_transform_dict.items() if pd.isnull(v)]\n",
    "tochange = df['user_id']\n",
    "df['user_id'] = tochange.map(user_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan)))\n",
    "\n",
    "keep_nan = [k for k, v in recipe_transform_dict.items() if pd.isnull(v)]\n",
    "tochange = df['recipe_id']\n",
    "df['recipe_id'] = tochange.map(recipe_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creation of the folds for k-fold validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "unique_users = df.user_id.unique()\n",
    "\n",
    "unique_users.sort(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "kf.get_n_splits(df)\n",
    "folds = list()\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    folds.append((X_train, X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here starts the actual programming of the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class popularity:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train(self,data):\n",
    "        data=data.sort_values('count_user',ascending=False)\n",
    "        self.pop=data[data.columns[1]].to_numpy()\n",
    "    def predict(self):\n",
    "        return self.pop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class Easer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, lambda_=0.5):\n",
    "        self.X = X_train\n",
    "\n",
    "        #X_train_t=X_train.copy().transpose()\n",
    "        G = X_train.T.dot(X_train)  # sparse\n",
    "        G = G.toarray()\n",
    "        #G= X_train.T.dot(X_train).toarray() # dense\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = scipy.linalg.inv(G)  # sparse\n",
    "        #P = np.linalg.inv(G) # dense\n",
    "        # dense diagonal retrieval (for some reason i cant get this to work on sparse matrixes something with the dimensions being wrong)\n",
    "        div = -np.diag(P)\n",
    "        self.B = P / div\n",
    "        self.B[diagIndices] = 0\n",
    "\n",
    "        self.pred = self.X * self.B\n",
    "\n",
    "    def predicts(self, xu):\n",
    "        #TODO give back the predicted vector given a user interaction vector\n",
    "        return xu * self.B\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8653\n",
      "12078\n",
      "done\n",
      "training took :  31.029282569885254 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "\n",
    "for f_idx, i in enumerate(folds):\n",
    "    start = time.time()\n",
    "    #for fold in folds: # removed for loop for testing\n",
    "    train_data = i[0]\n",
    "    ratings = train_data.rating\n",
    "    idx = (train_data.user_id, train_data.recipe_id)\n",
    "    print(len(df.user_id.unique()))\n",
    "    print(len(df.recipe_id.unique()))\n",
    "    #Here we have the user item matrix\n",
    "    X_train = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())),\n",
    "                                dtype=float)\n",
    "    #train model\n",
    "    model_pop=popularity()\n",
    "    model_pop.train(train_data)\n",
    "    model = Easer()\n",
    "    model.train(X_train)\n",
    "    print(\"done\")\n",
    "    end = time.time()\n",
    "    print(\"training took : \", end - start, \"s\")\n",
    "    datafile = open(\"D:\\\\results_aiproject\\\\data_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    pickle.dump(i, datafile)\n",
    "    modelfile = open(\"D:\\\\results_aiproject\\\\model_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    modelpopfile = open(\"D:\\\\results_aiproject\\\\model_pop_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    pickle.dump(model, modelfile)\n",
    "    pickle.dump(model_pop, modelpopfile)\n",
    "    datafile.close()\n",
    "    modelfile.close()\n",
    "    modelpopfile.close()\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.29692853e-05  1.68655999e-04 -6.49266221e-03 ...  3.51492863e-03\n",
      "  -8.03840436e-04 -7.51342849e-03]\n",
      " [-2.36305050e-05 -1.48826344e-05 -4.35269038e-04 ... -1.02803897e-03\n",
      "  -1.93835177e-04 -1.54964534e-03]\n",
      " [ 2.17502798e-04  9.49109850e-04 -1.66775783e-03 ...  5.38801763e-03\n",
      "  -2.91978342e-03  1.28300729e-02]\n",
      " ...\n",
      " [ 7.21354574e-05 -1.10500834e-03  5.29655483e-03 ... -2.47202061e-03\n",
      "   2.44627106e-03 -5.98272322e-04]\n",
      " [-2.29864448e-04  1.00715644e-03 -5.73450218e-03 ... -8.12282016e-05\n",
      "  -7.61354699e-04  6.23342607e-04]\n",
      " [ 4.54769058e-05  7.48103033e-04 -1.38832232e-03 ...  1.25124384e-03\n",
      "  -2.61584784e-05  6.97334873e-05]]\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load(open(\"D:\\\\results_aiproject\\\\data_fold0.pkl\", mode='rb'))\n",
    "model = pickle.load(open(\"D:\\\\results_aiproject\\\\model_fold0.pkl\", mode='rb'))\n",
    "\n",
    "# test_data=data[1]\n",
    "# temp_result=remove_single_interaction(test_data)\n",
    "# test_data.reset_index(drop=True, inplace=True)\n",
    "# removed_test_data=temp_result[0]\n",
    "# removed_recipes=temp_result[1]\n",
    "# ratings = removed_test_data.rating\n",
    "# idx = (removed_test_data.user_id, removed_test_data.recipe_id)\n",
    "# x_test=sparse.csc_matrix((ratings, idx), shape=(len(test_data.user_id.unique()), len(df.recipe_id.unique())), dtype=float)\n",
    "# y_pred = model.predicts(x_test)\n",
    "# print(y_pred)\n",
    "test_data = data[1]\n",
    "predict_data = data[0]\n",
    "ratings = predict_data.rating\n",
    "idx = (predict_data.user_id, predict_data.recipe_id)\n",
    "x_test = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())), dtype=float)\n",
    "y_pred = model.predicts(x_test)\n",
    "print(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@20 = 0.020594965675057208\n"
     ]
    }
   ],
   "source": [
    "#Evaluate recall@k\n",
    "#Do elementwise multiplication of top K predicts and true interactions\n",
    "K = 20\n",
    "total = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "for idx, interaction in test_data.iterrows():\n",
    "    user = interaction['user_id']\n",
    "    user_data = predict_data.loc[(predict_data['user_id'] == user)]\n",
    "    already_interacted_recipes = user_data[user_data.columns[1]].to_numpy()\n",
    "    predicted = y_pred[user]\n",
    "    np.put(predicted, already_interacted_recipes, -5)\n",
    "    ind = (-predicted).argsort()[:K]\n",
    "    recipe = interaction['recipe_id']\n",
    "    if (recipe in ind):\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    total += 1\n",
    "print(\"recall@%s = %s\" % (str(K), str(correct / total)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@20 = 0.00131242428321443\n"
     ]
    }
   ],
   "source": [
    "#recall score for popularity\n",
    "data = pickle.load(open(\"D:\\\\results_aiproject\\\\data_fold0.pkl\", mode='rb'))\n",
    "model = pickle.load(open(\"D:\\\\results_aiproject\\\\model_pop_fold0.pkl\", mode='rb'))\n",
    "test_data = data[1]\n",
    "predict_data = data[0]\n",
    "pop=model.predict()\n",
    "K = 20\n",
    "total = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "for idx, interaction in test_data.iterrows():\n",
    "    user = interaction['user_id']\n",
    "    user_data = predict_data.loc[(predict_data['user_id'] == user)]\n",
    "    already_interacted_recipes = user_data[user_data.columns[1]].to_numpy()\n",
    "    newpop=pop[:50]\n",
    "    newpop=newpop[~np.in1d(newpop,already_interacted_recipes)]\n",
    "    newpop=newpop[:K]\n",
    "    recipe = interaction['recipe_id']\n",
    "    if (recipe in newpop):\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    total += 1\n",
    "print(\"recall@%s = %s\" % (str(K), str(correct / total)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}