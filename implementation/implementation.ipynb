{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# project ai: Easer\n",
    "\n",
    "by Michiel TÃ©blick and thibaut Van Goethem\n",
    "\n",
    "In this notebook we will look at the easer model proposed at https://dl.acm.org/doi/pdf/10.1145/3308558.3313710.\n",
    "\n",
    "This model will be applied to a dataset from foods.com which containes a bunch of recipes with user ratings/reactions on them.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading and preprocessing the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of interactions in the full dataset:  1132367\n",
      "amount of recipes in the full dataset:  231637\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/RAW_interactions.csv')\n",
    "df.drop('review', axis=1, inplace=True)\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "df.reset_index()\n",
    "df.drop_duplicates(subset=['user_id', 'recipe_id'])\n",
    "print(\"amount of interactions in the full dataset: \",len(df))\n",
    "print(\"amount of recipes in the full dataset: \",len(df.recipe_id.unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set all ratings to 1 (even negative interactions are seen as interactions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df.loc[:,'rating'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below here are two ways to cut down on the amount of interactions that are used in this notebook\n",
    "- The first one randomly removes x% of the users,\n",
    "- The second one removes all user and recipes that have less than X amount of interaction containing them\n",
    "\n",
    "We opted for the second form as this is more representative of how the models should be used due to the lower amount if recipes but more reactions per recipe. Also the second choice is a deterministic way of removing data, which the first one is not.\n",
    "This does end up mostly giving slightly worse result compared to the first choice.\n",
    "\n",
    "The reason we need to remove data is because a matrix inversion is done, which can not be done in a smart way.\n",
    "Also the result of the inversion is not necessarily a sparse matrix so the full calculation needs to be done on dense matrices. This end up scaling O(n^3) in time complexity and O(n^2) for memory needed. n here is the amount of recipes.\n",
    "So running on the full dataset would require more than 200gb of ram which we do not have."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# # randomly drop a subset of data as we dont have enough resource to run the entire dataset\n",
    "# unique_recipes = df.recipe_id.unique()\n",
    "# subset = np.random.choice(unique_recipes, size=int(len(unique_recipes) / 10), replace=False, p=None)\n",
    "# # Keep only the recipes that were in the randomly sampled df\n",
    "# df = df[df['recipe_id'].isin(subset)]\n",
    "# df.reset_index()\n",
    "#\n",
    "# # Preprocessing step where we remove all recipes that only have a single review from a person that only has a single review\n",
    "# # This is done as these items will never be connected to other items and thus will never be recommended\n",
    "#\n",
    "# df['count_user'] = df.groupby(['recipe_id'])['recipe_id'].transform('size')\n",
    "# df['count_item'] = df.groupby(['user_id'])['user_id'].transform('size')\n",
    "# # 1121916 interaction in df after the and drop\n",
    "# # df = df.drop(df[(df['counts'] == 1) & (df['counts_user'] == 1)].index)\n",
    "#\n",
    "# # 884607 interactions after the or drop\n",
    "# df = df.drop(df[(df['count_item'] == 1) | (df['count_user'] == 1)].index)\n",
    "# df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "g1 = df.groupby('recipe_id', as_index=False)['user_id'].size()\n",
    "g1 = g1.rename({'size': 'count_item'}, axis='columns')\n",
    "g2 = df.groupby('user_id', as_index=False)['recipe_id'].size()\n",
    "g2 = g2.rename({'size': 'count_user'}, axis='columns')\n",
    "df = pd.merge(df, g1, how='left', on=['recipe_id'])\n",
    "df = pd.merge(df, g2, how='left', on=['user_id'])\n",
    "df = df[df['count_item'] >= 15]\n",
    "df = df[df['count_user'] >= 15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rescaling the id's\n",
    "The recipes and users don't go from 0 to amount so if we were to put this in a matrix we would get empty columns and rows. This is not that handy so we reindex both the user_id and recipe_ids\n",
    "\n",
    "This is a step we must not forget when entering the data in the model, as we also need to remap our input data using the same remapping that was used here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "userSet = set(df['user_id'].to_list())\n",
    "user_transform_dict = dict(map(reversed, enumerate(userSet)))\n",
    "recipeSet = set(df['recipe_id'].to_list())\n",
    "recipe_transform_dict = dict(map(reversed, enumerate(recipeSet)))\n",
    "recipe_dict = dict(enumerate(recipeSet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "keep_nan = [k for k, v in user_transform_dict.items() if pd.isnull(v)]\n",
    "tochange = df['user_id']\n",
    "df['user_id'] = tochange.map(user_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan)))\n",
    "\n",
    "keep_nan = [k for k, v in recipe_transform_dict.items() if pd.isnull(v)]\n",
    "tochange = df['recipe_id']\n",
    "df['recipe_id'] = tochange.map(recipe_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creation of the folds\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "kf.get_n_splits(df)\n",
    "folds = list()\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    folds.append((X_train, X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creation model\n",
    "Here we define the models used for the experiments. Both the easer predictor and a populaliry predictor are created. the popularity predictor is used as a baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class popularity:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train(self,data):\n",
    "        data=data.sort_values('count_user',ascending=False)\n",
    "        self.pop=data[data.columns[1]].to_numpy()\n",
    "    def predict(self):\n",
    "        return self.pop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Easer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, lambda_=0.5):\n",
    "        #Code here is a modified version of the code provided in the paper\n",
    "        self.X = X_train\n",
    "\n",
    "        G = X_train.T.dot(X_train)\n",
    "        G = G.toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = scipy.linalg.inv(G)\n",
    "        div = -np.diag(P)\n",
    "        self.B = P / div\n",
    "        self.B[diagIndices] = 0\n",
    "\n",
    "        self.pred = self.X * self.B\n",
    "\n",
    "    def predicts(self, xu):\n",
    "        return xu * self.B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## training models + k-fold validation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fold: 0\n",
      "training took :  39.41595792770386 s\n",
      "done fold: 1\n",
      "training took :  39.61205983161926 s\n",
      "done fold: 2\n",
      "training took :  39.19988489151001 s\n",
      "done fold: 3\n",
      "training took :  39.33319401741028 s\n",
      "done fold: 4\n",
      "training took :  38.85149812698364 s\n",
      "done fold: 5\n",
      "training took :  39.084100008010864 s\n",
      "done fold: 6\n",
      "training took :  39.282891035079956 s\n",
      "done fold: 7\n",
      "training took :  39.29134488105774 s\n",
      "done fold: 8\n",
      "training took :  38.910627126693726 s\n",
      "done fold: 9\n",
      "training took :  41.14596605300903 s\n"
     ]
    }
   ],
   "source": [
    "#Please enter the path here of where you will place the pickle files (with trailing /)\n",
    "data_path=\"../results_aiproject/\"\n",
    "for f_idx, fold_data in enumerate(folds):\n",
    "    start = time.time()\n",
    "    train_data = fold_data[0]\n",
    "    ratings = train_data.rating\n",
    "    idx = (train_data.user_id, train_data.recipe_id)\n",
    "    #Here we have the user item matrix\n",
    "    X_train = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())),\n",
    "                                dtype=float)\n",
    "    #train models\n",
    "    model_pop=popularity()\n",
    "    model_pop.train(train_data)\n",
    "    model = Easer()\n",
    "    model.train(X_train)\n",
    "    print(\"done fold:\",str(f_idx))\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"training took : \", end - start, \"s\")\n",
    "\n",
    "    #Dump data for later usage (note that the easer model files end up being pretty large (approx 5gb each))\n",
    "    datafile = open(data_path+\"data_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    pickle.dump(fold_data, datafile)\n",
    "    modelfile = open(data_path+\"model_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    modelpopfile = open(data_path+\"model_pop_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    pickle.dump(model, modelfile)\n",
    "    pickle.dump(model_pop, modelpopfile)\n",
    "    datafile.close()\n",
    "    modelfile.close()\n",
    "    modelpopfile.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation results of the folds\n",
    "\n",
    "Here we use recall@20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "K = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easer fold: 0, recall@20 = 0.022748687575716787\n",
      "easer fold: 1, recall@20 = 0.02385920043074438\n",
      "easer fold: 2, recall@20 = 0.025104320904563198\n",
      "easer fold: 3, recall@20 = 0.024902409476376362\n",
      "easer fold: 4, recall@20 = 0.023556333288464126\n",
      "easer fold: 5, recall@20 = 0.025037017095167587\n",
      "easer fold: 6, recall@20 = 0.023926504240139992\n",
      "easer fold: 7, recall@20 = 0.02426302328711805\n",
      "easer fold: 8, recall@20 = 0.02335442186027729\n",
      "easer fold: 9, recall@20 = 0.023825548526046573\n",
      "mean over 10 folds:  0.024057746668461433\n",
      "standard deviation over 10 folds:  0.0007334957383737352\n"
     ]
    }
   ],
   "source": [
    "result_list=list()\n",
    "for i in range(10):\n",
    "    data = pickle.load(open(data_path+\"data_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "    model = pickle.load(open(data_path+\"model_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "\n",
    "    test_data = data[1]\n",
    "    predict_data = data[0]\n",
    "    ratings = predict_data.rating\n",
    "    idx = (predict_data.user_id, predict_data.recipe_id)\n",
    "    x_test = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())), dtype=float)\n",
    "    y_pred = model.predicts(x_test)\n",
    "    # print(y_pred)\n",
    "\n",
    "    #Evaluate recall@k\n",
    "    #Do elementwise multiplication of top K predicts and true interactions\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for idx, interaction in test_data.iterrows():\n",
    "        user = interaction['user_id']\n",
    "        user_data = predict_data.loc[(predict_data['user_id'] == user)]\n",
    "        already_interacted_recipes = user_data[user_data.columns[1]].to_numpy()\n",
    "        predicted = y_pred[user]\n",
    "        np.put(predicted, already_interacted_recipes, -5)\n",
    "        ind = (-predicted).argsort()[:K]\n",
    "        recipe = interaction['recipe_id']\n",
    "        if (recipe in ind):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "        total += 1\n",
    "    result_list.append(correct / total)\n",
    "    print(\"easer fold: %s, recall@%s = %s\" % (str(i),str(K), str(correct / total)))\n",
    "print(\"mean over 10 folds: \",str(st.mean(result_list)))\n",
    "print(\"standard deviation over 10 folds: \",str(st.pstdev(result_list)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity fold: 0, recall@20 = 0.0015143357114012653\n",
      "popularity fold: 1, recall@20 = 0.0017162471395881006\n",
      "popularity fold: 2, recall@20 = 0.0015143357114012653\n",
      "popularity fold: 3, recall@20 = 0.0012451204738188181\n",
      "popularity fold: 4, recall@20 = 0.0019854623771705477\n",
      "popularity fold: 5, recall@20 = 0.0014133799973078476\n",
      "popularity fold: 6, recall@20 = 0.002894063804011307\n",
      "popularity fold: 7, recall@20 = 0.0019854623771705477\n",
      "popularity fold: 8, recall@20 = 0.0019181585677749361\n",
      "popularity fold: 9, recall@20 = 0.0012114685691210123\n",
      "mean over 10 folds:  0.0017398034728765648\n",
      "standard deviation over 10 folds:  0.0004708982581915345\n"
     ]
    }
   ],
   "source": [
    "#recall score for popularity\n",
    "result_list_pop=list()\n",
    "for i in range(10):\n",
    "    data = pickle.load(open(data_path+\"data_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "    model = pickle.load(open(data_path+\"model_pop_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "    test_data = data[1]\n",
    "    predict_data = data[0]\n",
    "    pop=model.predict()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for idx, interaction in test_data.iterrows():\n",
    "        user = interaction['user_id']\n",
    "        user_data = predict_data.loc[(predict_data['user_id'] == user)]\n",
    "        already_interacted_recipes = user_data[user_data.columns[1]].to_numpy()\n",
    "        newpop=pop[:50]\n",
    "        newpop=newpop[~np.in1d(newpop,already_interacted_recipes)]\n",
    "        newpop=newpop[:K]\n",
    "        recipe = interaction['recipe_id']\n",
    "        if (recipe in newpop):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "        total += 1\n",
    "    result_list_pop.append(correct / total)\n",
    "    print(\"popularity fold: %s, recall@%s = %s\" % (str(i),str(K), str(correct / total)))\n",
    "print(\"mean over 10 folds: \",str(st.mean(result_list_pop)))\n",
    "print(\"standard deviation over 10 folds: \",str(st.pstdev(result_list_pop)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next section is a demonstration that selects a random user and makes a recommendation prediction for this user."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                     name  \\\n5047                                    amish white bread   \n17450                          barb s best zucchini bread   \n30137                     brown rice and lentil casserole   \n39655                 cheese tortellini pesto pasta salad   \n45648   chicken scaloppine with lemon glaze   low fat ...   \n50107    chocolate chocolate chip sour cream banana bread   \n57151                                 confetti orzo salad   \n57732   copycat olive garden minestrone soup by todd w...   \n72879                                  dot s corn muffins   \n78584                                 easy venison steaks   \n92324    gingerbread  for cookies or a  gingerbread house   \n101352                                ham   cheese quiche   \n103312                        healthy bean soup with kale   \n140525                                  munchies  lentils   \n190501                             snickerdoodle blondies   \n\n                                              ingredients  \n5047    ['dry yeast', 'water', 'sugar', 'salt', 'short...  \n17450   ['eggs', 'sugar', 'zucchini', 'vegetable oil',...  \n30137   ['chicken broth', 'lentils', 'brown rice', 'on...  \n39655   ['artichoke hearts', 'grape tomatoes', 'black ...  \n45648   ['boneless skinless chicken breasts', 'dijon m...  \n50107   ['butter', 'sugar', 'vanilla extract', 'eggs',...  \n57151   ['orzo pasta', 'olive oil', 'lemon juice', 'le...  \n57732   ['olive oil', 'white onion', 'zucchini', 'ital...  \n72879   ['all-purpose flour', 'cornmeal', 'sugar', 'ba...  \n78584   ['flour', 'mrs. dash seasoning mix', 'garlic s...  \n92324   ['sugar', 'molasses', 'ginger', 'allspice', 'c...  \n101352  ['eggs', 'milk', 'salt', 'pepper', 'cooked ham...  \n103312  ['olive oil', 'garlic cloves', 'yellow onion',...  \n140525  ['lentils', 'water', 'canola oil', 'coarse sal...  \n190501  ['all-purpose flour', 'baking powder', 'cinnam...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5047</th>\n      <td>amish white bread</td>\n      <td>['dry yeast', 'water', 'sugar', 'salt', 'short...</td>\n    </tr>\n    <tr>\n      <th>17450</th>\n      <td>barb s best zucchini bread</td>\n      <td>['eggs', 'sugar', 'zucchini', 'vegetable oil',...</td>\n    </tr>\n    <tr>\n      <th>30137</th>\n      <td>brown rice and lentil casserole</td>\n      <td>['chicken broth', 'lentils', 'brown rice', 'on...</td>\n    </tr>\n    <tr>\n      <th>39655</th>\n      <td>cheese tortellini pesto pasta salad</td>\n      <td>['artichoke hearts', 'grape tomatoes', 'black ...</td>\n    </tr>\n    <tr>\n      <th>45648</th>\n      <td>chicken scaloppine with lemon glaze   low fat ...</td>\n      <td>['boneless skinless chicken breasts', 'dijon m...</td>\n    </tr>\n    <tr>\n      <th>50107</th>\n      <td>chocolate chocolate chip sour cream banana bread</td>\n      <td>['butter', 'sugar', 'vanilla extract', 'eggs',...</td>\n    </tr>\n    <tr>\n      <th>57151</th>\n      <td>confetti orzo salad</td>\n      <td>['orzo pasta', 'olive oil', 'lemon juice', 'le...</td>\n    </tr>\n    <tr>\n      <th>57732</th>\n      <td>copycat olive garden minestrone soup by todd w...</td>\n      <td>['olive oil', 'white onion', 'zucchini', 'ital...</td>\n    </tr>\n    <tr>\n      <th>72879</th>\n      <td>dot s corn muffins</td>\n      <td>['all-purpose flour', 'cornmeal', 'sugar', 'ba...</td>\n    </tr>\n    <tr>\n      <th>78584</th>\n      <td>easy venison steaks</td>\n      <td>['flour', 'mrs. dash seasoning mix', 'garlic s...</td>\n    </tr>\n    <tr>\n      <th>92324</th>\n      <td>gingerbread  for cookies or a  gingerbread house</td>\n      <td>['sugar', 'molasses', 'ginger', 'allspice', 'c...</td>\n    </tr>\n    <tr>\n      <th>101352</th>\n      <td>ham   cheese quiche</td>\n      <td>['eggs', 'milk', 'salt', 'pepper', 'cooked ham...</td>\n    </tr>\n    <tr>\n      <th>103312</th>\n      <td>healthy bean soup with kale</td>\n      <td>['olive oil', 'garlic cloves', 'yellow onion',...</td>\n    </tr>\n    <tr>\n      <th>140525</th>\n      <td>munchies  lentils</td>\n      <td>['lentils', 'water', 'canola oil', 'coarse sal...</td>\n    </tr>\n    <tr>\n      <th>190501</th>\n      <td>snickerdoodle blondies</td>\n      <td>['all-purpose flour', 'baking powder', 'cinnam...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                                     name  \\\n574                   whatever floats your boat  brownies   \n17179                       banana chocolate chip muffins   \n45020                               chicken packets  oamc   \n89197   fudge crinkles  a great 4 ingredient cake mix ...   \n115303                   jo mama s world famous spaghetti   \n167258                                    pumpkin pie dip   \n189309                        slow cooker beef short ribs   \n193828                        spanish chicken   rice bake   \n203644                              sunflower centerpiece   \n228062                                    wonderful salsa   \n\n                                              ingredients  \n574     ['butter', 'unsweetened cocoa', 'sugar', 'eggs...  \n17179   ['bananas', 'egg', 'low-fat buttermilk', 'gran...  \n45020   ['cooked chicken', 'cream cheese', 'chives', '...  \n89197   [\"devil's food cake mix\", 'vegetable oil', 'eg...  \n115303  ['italian sausage', 'onion', 'garlic cloves', ...  \n167258  ['cream cheese', 'powdered sugar', 'pumpkin pi...  \n189309  ['flour', 'salt', 'pepper', 'boneless beef sho...  \n193828  ['cream of chicken soup', 'salsa', 'water', 'w...  \n203644  ['chocolate cake', 'chocolate frosting', 'choc...  \n228062  ['tomatoes', 'onions', 'green peppers', 'jalap...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>574</th>\n      <td>whatever floats your boat  brownies</td>\n      <td>['butter', 'unsweetened cocoa', 'sugar', 'eggs...</td>\n    </tr>\n    <tr>\n      <th>17179</th>\n      <td>banana chocolate chip muffins</td>\n      <td>['bananas', 'egg', 'low-fat buttermilk', 'gran...</td>\n    </tr>\n    <tr>\n      <th>45020</th>\n      <td>chicken packets  oamc</td>\n      <td>['cooked chicken', 'cream cheese', 'chives', '...</td>\n    </tr>\n    <tr>\n      <th>89197</th>\n      <td>fudge crinkles  a great 4 ingredient cake mix ...</td>\n      <td>[\"devil's food cake mix\", 'vegetable oil', 'eg...</td>\n    </tr>\n    <tr>\n      <th>115303</th>\n      <td>jo mama s world famous spaghetti</td>\n      <td>['italian sausage', 'onion', 'garlic cloves', ...</td>\n    </tr>\n    <tr>\n      <th>167258</th>\n      <td>pumpkin pie dip</td>\n      <td>['cream cheese', 'powdered sugar', 'pumpkin pi...</td>\n    </tr>\n    <tr>\n      <th>189309</th>\n      <td>slow cooker beef short ribs</td>\n      <td>['flour', 'salt', 'pepper', 'boneless beef sho...</td>\n    </tr>\n    <tr>\n      <th>193828</th>\n      <td>spanish chicken   rice bake</td>\n      <td>['cream of chicken soup', 'salsa', 'water', 'w...</td>\n    </tr>\n    <tr>\n      <th>203644</th>\n      <td>sunflower centerpiece</td>\n      <td>['chocolate cake', 'chocolate frosting', 'choc...</td>\n    </tr>\n    <tr>\n      <th>228062</th>\n      <td>wonderful salsa</td>\n      <td>['tomatoes', 'onions', 'green peppers', 'jalap...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "# read recipe data and load pre-trained model\n",
    "df_recipes = pd.read_csv('../data/RAW_recipes.csv')\n",
    "df_recipes.drop(['minutes', 'contributor_id', 'submitted', 'tags',\n",
    "                 'nutrition', 'n_steps', 'steps', 'description', 'n_ingredients'], axis=1, inplace=True)\n",
    "data = pickle.load(open(data_path+\"data_fold0.pkl\", mode='rb'))\n",
    "model = pickle.load(open(data_path+\"model_fold0.pkl\", mode='rb'))\n",
    "predict_data = data[0]\n",
    "ratings = predict_data.rating\n",
    "idx = (predict_data.user_id, predict_data.recipe_id)\n",
    "x_train = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())), dtype=float)\n",
    "\n",
    "# get random user and make prediction\n",
    "random_user = x_train.getrow(random.randint(0, len(df.user_id.unique())))\n",
    "prediction = model.predicts(random_user)[0]\n",
    "interacted_recipes = []\n",
    "for recipe_id in random_user.indices:\n",
    "    interacted_recipes.append(recipe_dict[recipe_id])\n",
    "    prediction[recipe_id] = -100000\n",
    "\n",
    "\n",
    "top_index = (-prediction).argsort()[:10]\n",
    "recommended_recipes = []\n",
    "for recipe_id in top_index:\n",
    "    recommended_recipes.append(recipe_dict[recipe_id])\n",
    "\n",
    "# get interacted recipes and recommended recipes\n",
    "user_interactions = df_recipes[df_recipes['id'].isin(interacted_recipes)].drop('id', axis=1)\n",
    "user_recommendations = df_recipes[df_recipes['id'].isin(recommended_recipes)].drop('id', axis=1)\n",
    "\n",
    "display(user_interactions)\n",
    "display(user_recommendations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}