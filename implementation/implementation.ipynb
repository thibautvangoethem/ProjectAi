{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# project ai: Easer\n",
    "\n",
    "by Michiel TÃ©blick and thibaut Van Goethem\n",
    "\n",
    "In this notebook we will look at the easer model proposed at https://dl.acm.org/doi/pdf/10.1145/3308558.3313710.\n",
    "\n",
    "This model will be applied to a dataset from foods.com which containes a bunch of recipes with user ratings/reactions on them.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading and preprocessing the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of interactions in the full dataset:  1132367\n",
      "amount of recipes in the full dataset:  231637\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/RAW_interactions.csv')\n",
    "df.drop('review', axis=1, inplace=True)\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "df.reset_index()\n",
    "df.drop_duplicates(subset=['user_id', 'recipe_id'])\n",
    "print(\"amount of interactions in the full dataset: \",len(df))\n",
    "print(\"amount of recipes in the full dataset: \",len(df.recipe_id.unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set all ratings to 1 (even negative interactions are seen as interactions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df.loc[:,'rating'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below here are two ways to cut down on the amount of interactions that are used in this notebook\n",
    "- The first one randomly removes x% of the users,\n",
    "- The second one removes all user and recipes that have less than X amount of interaction containing them\n",
    "\n",
    "We opted for the second form as this is more representative of how the models should be used due to the lower amount if recipes but more reactions per recipe. Also the second choice is a deterministic way of removing data, which the first one is not.\n",
    "This does end up mostly giving slightly worse result compared to the first choice.\n",
    "\n",
    "The reason we need to remove data is because a matrix inversion is done, which can not be done in a smart way.\n",
    "Also the result of the inversion is not necessarily a sparse matrix so the full calculation needs to be done on dense matrices. This end up scaling O(n^3) in time complexity and O(n^2) for memory needed. n here is the amount of recipes.\n",
    "So running on the full dataset would require more than 200gb of ram which we do not have."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# # randomly drop a subset of data as we dont have enough resource to run the entire dataset\n",
    "# unique_recipes = df.recipe_id.unique()\n",
    "# subset = np.random.choice(unique_recipes, size=int(len(unique_recipes) / 10), replace=False, p=None)\n",
    "# # Keep only the recipes that were in the randomly sampled df\n",
    "# df = df[df['recipe_id'].isin(subset)]\n",
    "# df.reset_index()\n",
    "#\n",
    "# # Preprocessing step where we remove all recipes that only have a single review from a person that only has a single review\n",
    "# # This is done as these items will never be connected to other items and thus will never be recommended\n",
    "#\n",
    "# df['count_user'] = df.groupby(['recipe_id'])['recipe_id'].transform('size')\n",
    "# df['count_item'] = df.groupby(['user_id'])['user_id'].transform('size')\n",
    "# # 1121916 interaction in df after the and drop\n",
    "# # df = df.drop(df[(df['counts'] == 1) & (df['counts_user'] == 1)].index)\n",
    "#\n",
    "# # 884607 interactions after the or drop\n",
    "# df = df.drop(df[(df['count_item'] == 1) | (df['count_user'] == 1)].index)\n",
    "# df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "g1 = df.groupby('recipe_id', as_index=False)['user_id'].size()\n",
    "g1 = g1.rename({'size': 'count_item'}, axis='columns')\n",
    "g2 = df.groupby('user_id', as_index=False)['recipe_id'].size()\n",
    "g2 = g2.rename({'size': 'count_user'}, axis='columns')\n",
    "df = pd.merge(df, g1, how='left', on=['recipe_id'])\n",
    "df = pd.merge(df, g2, how='left', on=['user_id'])\n",
    "df = df[df['count_item'] >= 15]\n",
    "df = df[df['count_user'] >= 15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rescaling the id's\n",
    "The recipes and users don't go from 0 to amount so if we were to put this in a matrix we would get empty columns and rows. This is not that handy so we reindex both the user_id and recipe_ids\n",
    "\n",
    "This is a step we must not forget when entering the data in the model, as we also need to remap our input data using the same remapping that was used here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "userSet = set(df['user_id'].to_list())\n",
    "user_transform_dict = dict(map(reversed, enumerate(userSet)))\n",
    "recipeSet = set(df['recipe_id'].to_list())\n",
    "recipe_transform_dict = dict(map(reversed, enumerate(recipeSet)))\n",
    "recipe_dict = dict(enumerate(recipeSet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "keep_nan = [k for k, v in user_transform_dict.items() if pd.isnull(v)]\n",
    "tochange = df['user_id']\n",
    "df['user_id'] = tochange.map(user_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan)))\n",
    "\n",
    "keep_nan = [k for k, v in recipe_transform_dict.items() if pd.isnull(v)]\n",
    "tochange = df['recipe_id']\n",
    "df['recipe_id'] = tochange.map(recipe_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creation of the folds\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "kf.get_n_splits(df)\n",
    "folds = list()\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train = df.iloc[train_index]\n",
    "    X_test = df.iloc[test_index]\n",
    "    folds.append((X_train, X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creation model\n",
    "Here we define the models used for the experiments. Both the easer predictor and a populaliry predictor are created. the popularity predictor is used as a baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class popularity:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train(self,data):\n",
    "        data=data.sort_values('count_user',ascending=False)\n",
    "        self.pop=data[data.columns[1]].to_numpy()\n",
    "    def predict(self):\n",
    "        return self.pop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Easer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, lambda_=0.5):\n",
    "        #Code here is a modified version of the code provided in the paper\n",
    "        self.X = X_train\n",
    "\n",
    "        G = X_train.T.dot(X_train)\n",
    "        G = G.toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = scipy.linalg.inv(G)\n",
    "        div = -np.diag(P)\n",
    "        self.B = P / div\n",
    "        self.B[diagIndices] = 0\n",
    "\n",
    "        self.pred = self.X * self.B\n",
    "\n",
    "    def predicts(self, xu):\n",
    "        return xu * self.B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## training models + k-fold validation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fold: 0\n",
      "training took :  39.41595792770386 s\n",
      "done fold: 1\n",
      "training took :  39.61205983161926 s\n",
      "done fold: 2\n",
      "training took :  39.19988489151001 s\n",
      "done fold: 3\n",
      "training took :  39.33319401741028 s\n",
      "done fold: 4\n",
      "training took :  38.85149812698364 s\n",
      "done fold: 5\n",
      "training took :  39.084100008010864 s\n",
      "done fold: 6\n",
      "training took :  39.282891035079956 s\n",
      "done fold: 7\n",
      "training took :  39.29134488105774 s\n",
      "done fold: 8\n",
      "training took :  38.910627126693726 s\n",
      "done fold: 9\n",
      "training took :  41.14596605300903 s\n"
     ]
    }
   ],
   "source": [
    "#Please enter the path here of where you will place the pickle files (with trailing /)\n",
    "data_path=\"../results_aiproject/\"\n",
    "for f_idx, fold_data in enumerate(folds):\n",
    "    start = time.time()\n",
    "    train_data = fold_data[0]\n",
    "    ratings = train_data.rating\n",
    "    idx = (train_data.user_id, train_data.recipe_id)\n",
    "    #Here we have the user item matrix\n",
    "    X_train = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())),\n",
    "                                dtype=float)\n",
    "    #train models\n",
    "    model_pop=popularity()\n",
    "    model_pop.train(train_data)\n",
    "    model = Easer()\n",
    "    model.train(X_train)\n",
    "    print(\"done fold:\",str(f_idx))\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"training took : \", end - start, \"s\")\n",
    "\n",
    "    #Dump data for later usage (note that the easer model files end up being pretty large (approx 5gb each))\n",
    "    datafile = open(data_path+\"data_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    pickle.dump(fold_data, datafile)\n",
    "    modelfile = open(data_path+\"model_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    modelpopfile = open(data_path+\"model_pop_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    pickle.dump(model, modelfile)\n",
    "    pickle.dump(model_pop, modelpopfile)\n",
    "    datafile.close()\n",
    "    modelfile.close()\n",
    "    modelpopfile.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation results of the folds\n",
    "\n",
    "Here we use recall@20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "K = 20\n",
    "K2 = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easer fold: 0, recall@20 = 0.022748687575716787\n",
      "easer fold: 0, recall@50 = 0.03910351325885045\n",
      "easer fold: 0, ndcg@100 = 0.016130832670903584\n",
      "\n",
      "easer fold: 1, recall@20 = 0.02385920043074438\n",
      "easer fold: 1, recall@50 = 0.04135819087360344\n",
      "easer fold: 1, ndcg@100 = 0.017451790004165094\n",
      "\n",
      "easer fold: 2, recall@20 = 0.025104320904563198\n",
      "easer fold: 2, recall@50 = 0.04189662134876834\n",
      "easer fold: 2, ndcg@100 = 0.017158011216005745\n",
      "\n",
      "easer fold: 3, recall@20 = 0.024902409476376362\n",
      "easer fold: 3, recall@50 = 0.042367748014537625\n",
      "easer fold: 3, ndcg@100 = 0.017579789902018188\n",
      "\n",
      "easer fold: 4, recall@20 = 0.023556333288464126\n",
      "easer fold: 4, recall@50 = 0.03920446897294387\n",
      "easer fold: 4, ndcg@100 = 0.016525008367278982\n",
      "\n",
      "easer fold: 5, recall@20 = 0.025037017095167587\n",
      "easer fold: 5, recall@50 = 0.0416610580158837\n",
      "easer fold: 5, ndcg@100 = 0.01737077492308182\n",
      "\n",
      "easer fold: 6, recall@20 = 0.023926504240139992\n",
      "easer fold: 6, recall@50 = 0.04135819087360344\n",
      "easer fold: 6, ndcg@100 = 0.017025206686497357\n",
      "\n",
      "easer fold: 7, recall@20 = 0.02426302328711805\n",
      "easer fold: 7, recall@50 = 0.04098801992192758\n",
      "easer fold: 7, ndcg@100 = 0.017141541076918627\n",
      "\n",
      "easer fold: 8, recall@20 = 0.02335442186027729\n",
      "easer fold: 8, recall@50 = 0.04081976039843855\n",
      "easer fold: 8, ndcg@100 = 0.01668299814270219\n",
      "\n",
      "easer fold: 9, recall@20 = 0.023825548526046573\n",
      "easer fold: 9, recall@50 = 0.04041593754206488\n",
      "easer fold: 9, ndcg@100 = 0.017037657058366434\n",
      "\n",
      "mean recall@20 over 10 folds:  0.024057746668461433\n",
      "mean recall@50 over 10 folds:  0.04091735092206219\n",
      "mean ndcg@100 over 10 folds:  0.017010361004793802\n",
      "\n",
      "standard deviation recall@20 over 10 folds:  0.0007334957383737352\n",
      "standard deviation recall@50 over 10 folds:  0.0010244172634828502\n",
      "standard deviation ndcg@100 over 10 folds:  0.0004248864559279853\n"
     ]
    }
   ],
   "source": [
    "result_list_K = list()\n",
    "result_list_K2 = list()\n",
    "result_ndcg = list()\n",
    "for i in range(k):\n",
    "\n",
    "    #Evaluate recall@k\n",
    "    #Do elementwise multiplication of top K predicts and true interactions\n",
    "\n",
    "    data = pickle.load(open(data_path+\"data_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "    model = pickle.load(open(data_path+\"model_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "\n",
    "    test_data = data[1]\n",
    "    predict_data = data[0]\n",
    "    total = len(test_data)\n",
    "\n",
    "    ratings = predict_data.rating\n",
    "    idx = (predict_data.user_id, predict_data.recipe_id)\n",
    "    X_train = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())), dtype=float)\n",
    "    y_pred = model.pred\n",
    "\n",
    "    ratings_test = test_data.rating\n",
    "    idx_test = (test_data.user_id, test_data.recipe_id)\n",
    "    X_test = sparse.csc_matrix((ratings_test, idx_test), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())), dtype=np.single)\n",
    "\n",
    "    interacted_recipes = (X_train == 1).toarray()\n",
    "    y_pred[interacted_recipes] = -100000\n",
    "    idx_top_scores = (-y_pred).argsort()[:,:100]\n",
    "    dense_X_test = X_test.toarray()\n",
    "\n",
    "    correct_K = 0\n",
    "    correct_K2 = 0\n",
    "    ndcg = 0\n",
    "\n",
    "    for idx, row in enumerate(idx_top_scores):\n",
    "        for rank, index in enumerate(row):\n",
    "            if dense_X_test[idx][index] == 1:\n",
    "                if rank < K:\n",
    "                    correct_K += 1\n",
    "                if rank < K2:\n",
    "                    correct_K2 += 1\n",
    "                ndcg += 1/(math.log2(rank+2))\n",
    "\n",
    "    result_list_K.append(correct_K / total)\n",
    "    result_list_K2.append(correct_K2 / total)\n",
    "    result_ndcg.append(ndcg / total)\n",
    "\n",
    "    print(\"easer fold: %s, recall@%s = %s\" % (str(i), str(K), str(correct_K / total)))\n",
    "    print(\"easer fold: %s, recall@%s = %s\" % (str(i), str(K2), str(correct_K2 / total)))\n",
    "    print(\"easer fold: %s, ndcg@%s = %s\" % (str(i), 100, str(ndcg / total)), end=\"\\n\\n\")\n",
    "\n",
    "print(\"mean recall@%s over 10 folds: \" % str(K), str(st.mean(result_list_K)))\n",
    "print(\"mean recall@%s over 10 folds: \" % str(K2), str(st.mean(result_list_K2)))\n",
    "print(\"mean ndcg@%s over 10 folds: \" % str(100), str(st.mean(result_ndcg)), end=\"\\n\\n\")\n",
    "print(\"standard deviation recall@%s over 10 folds: \" % str(K), str(st.pstdev(result_list_K)))\n",
    "print(\"standard deviation recall@%s over 10 folds: \" % str(K2), str(st.pstdev(result_list_K2)))\n",
    "print(\"standard deviation ndcg@%s over 10 folds: \" % str(100), str(st.pstdev(result_ndcg)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity fold: 0, recall@20 = 0.0015143357114012653\n",
      "popularity fold: 0, recall@50 = 0.004071880468434513\n",
      "popularity fold: 0, ndcg@100 = 0.0018210543457153686\n",
      "\n",
      "popularity fold: 1, recall@20 = 0.0017162471395881006\n",
      "popularity fold: 1, recall@50 = 0.0036680576120608427\n",
      "popularity fold: 1, ndcg@100 = 0.0017132632802516633\n",
      "\n",
      "popularity fold: 2, recall@20 = 0.0015143357114012653\n",
      "popularity fold: 2, recall@50 = 0.004139184277830125\n",
      "popularity fold: 2, ndcg@100 = 0.0015943254974658983\n",
      "\n",
      "popularity fold: 3, recall@20 = 0.0012451204738188181\n",
      "popularity fold: 3, recall@50 = 0.003869969040247678\n",
      "popularity fold: 3, ndcg@100 = 0.0016849984544427294\n",
      "\n",
      "popularity fold: 4, recall@20 = 0.0019854623771705477\n",
      "popularity fold: 4, recall@50 = 0.004071880468434513\n",
      "popularity fold: 4, ndcg@100 = 0.0019041114696843771\n",
      "\n",
      "popularity fold: 5, recall@20 = 0.0014133799973078476\n",
      "popularity fold: 5, recall@50 = 0.0036680576120608427\n",
      "popularity fold: 5, ndcg@100 = 0.0015687299402064106\n",
      "\n",
      "popularity fold: 6, recall@20 = 0.002894063804011307\n",
      "popularity fold: 6, recall@50 = 0.005115089514066497\n",
      "popularity fold: 6, ndcg@100 = 0.002112740028731828\n",
      "\n",
      "popularity fold: 7, recall@20 = 0.0019854623771705477\n",
      "popularity fold: 7, recall@50 = 0.004879526181181855\n",
      "popularity fold: 7, ndcg@100 = 0.0018803926090403705\n",
      "\n",
      "popularity fold: 8, recall@20 = 0.0019181585677749361\n",
      "popularity fold: 8, recall@50 = 0.00467761475299502\n",
      "popularity fold: 8, ndcg@100 = 0.0019345684699538103\n",
      "\n",
      "popularity fold: 9, recall@20 = 0.0012114685691210123\n",
      "popularity fold: 9, recall@50 = 0.00376901332615426\n",
      "popularity fold: 9, ndcg@100 = 0.0016404860128678164\n",
      "\n",
      "mean recall@20 over 10 folds:  0.0017398034728765648\n",
      "mean recall@50 over 10 folds:  0.0041930273253466144\n",
      "mean ndcg@100 over 10 folds:  0.0017854670108360272\n",
      "\n",
      "standard deviation recall@20 over 10 folds:  0.0004708982581915345\n",
      "standard deviation recall@50 over 10 folds:  0.000492330931023734\n",
      "standard deviation ndcg@100 over 10 folds:  0.00016538728602640625\n"
     ]
    }
   ],
   "source": [
    "#recall score for popularity\n",
    "result_list_pop_K=list()\n",
    "result_list_pop_K2=list()\n",
    "result_list_pop_ndcg=list()\n",
    "for i in range(k):\n",
    "    data = pickle.load(open(data_path+\"data_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "    model = pickle.load(open(data_path+\"model_pop_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "    test_data = data[1]\n",
    "    predict_data = data[0]\n",
    "    pop=model.predict()\n",
    "    total = 0\n",
    "    correct_K = 0\n",
    "    correct_K2 = 0\n",
    "    ndcg = 0\n",
    "    for idx, interaction in test_data.iterrows():\n",
    "        user = interaction['user_id']\n",
    "        user_data = predict_data.loc[(predict_data['user_id'] == user)]\n",
    "        already_interacted_recipes = user_data[user_data.columns[1]].to_numpy()\n",
    "        newpop = pop[:150]\n",
    "        newpop = newpop[~np.in1d(newpop,already_interacted_recipes)]\n",
    "        newpop_K = newpop[:K]\n",
    "        newpop_K2 = newpop[:K2]\n",
    "        newpop_ndcg = newpop[:100]\n",
    "        recipe = interaction['recipe_id']\n",
    "        if recipe in newpop_K:\n",
    "            correct_K += 1\n",
    "        if recipe in newpop_K2:\n",
    "            correct_K2 += 1\n",
    "        if recipe in newpop_ndcg:\n",
    "            ndcg += 1/(math.log2(np.where(newpop_ndcg == recipe)[0]+2))\n",
    "        total += 1\n",
    "    result_list_pop_K.append(correct_K / total)\n",
    "    result_list_pop_K2.append(correct_K2 / total)\n",
    "    result_list_pop_ndcg.append(ndcg / total)\n",
    "    print(\"popularity fold: %s, recall@%s = %s\" % (str(i),str(K), str(correct_K / total)))\n",
    "    print(\"popularity fold: %s, recall@%s = %s\" % (str(i),str(K2), str(correct_K2 / total)))\n",
    "    print(\"popularity fold: %s, ndcg@%s = %s\" % (str(i),str(100), str(ndcg / total)), end=\"\\n\\n\")\n",
    "\n",
    "print(\"mean recall@%s over 10 folds: \" % str(K), str(st.mean(result_list_pop_K)))\n",
    "print(\"mean recall@%s over 10 folds: \" % str(K2), str(st.mean(result_list_pop_K2)))\n",
    "print(\"mean ndcg@%s over 10 folds: \" % str(100), str(st.mean(result_list_pop_ndcg)), end=\"\\n\\n\")\n",
    "print(\"standard deviation recall@%s over 10 folds: \" % str(K), str(st.pstdev(result_list_pop_K)))\n",
    "print(\"standard deviation recall@%s over 10 folds: \" % str(K2), str(st.pstdev(result_list_pop_K2)))\n",
    "print(\"standard deviation ndcg@%s over 10 folds: \" % str(100), str(st.pstdev(result_list_pop_ndcg)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next section is a demonstration that selects a random user and makes a recommendation prediction for this user."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     name  \\\n749                                      1 pan fudge cake   \n20502                         beef patties in onion gravy   \n21785                          berghoff s creamed spinach   \n23559                     bill knapp s au gratin potatoes   \n28764                              bri s cheddar meatloaf   \n31158                        buffalo chicken mac n cheese   \n31989                     buttered egg noodles  best ever   \n33802                              cajun style oven fries   \n40857                        cheesy stuffed summer squash   \n45081                       chicken parmesan foil packets   \n60718                            cranberry orange muffins   \n65338                        crock pot beef burgundy stew   \n65678                        crock pot chocolate mud cake   \n70732            delicious blue cheese broccoli casserole   \n73721                      drunken garlic crock pot roast   \n96667          greek potatoes  oven roasted and delicious   \n98399                                 grilled cauliflower   \n104405            heavenly chocolate raspberry bundt cake   \n115997  just like tony packos cabbage rolls crock pot ...   \n117944     kittencal s 5 minute cinnamon flop brunch cake   \n118135            kittencal s greek lemony rice with feta   \n118247           kittencal s perfect prime rib roast beef   \n120852                   leg of lamb boneless greek style   \n128716                            make ahead turkey gravy   \n132364             mean chef s pineapple upside down cake   \n136914                mititei  small ground beef sausages   \n141567                       my crock pot spaghetti sauce   \n145841                           nutty soda cracker candy   \n150392  our daily bread in a crock   weekly make and b...   \n158366                             perfect microwave rice   \n159071            pfeffernusse  german pepper nut cookies   \n173448                                        ribs my way   \n175222                           roasted brussels sprouts   \n184973                              shiny chocolate glaze   \n189313                  slow cooker beef tips and noodles   \n208120                                take out fried rice   \n213826                         to die for crock pot roast   \n217918                   turkey breakfast sausage patties   \n\n                                              ingredients  \n749     ['sugar', 'cocoa', 'baking soda', 'flour', 'sa...  \n20502   ['ground beef', 'egg', 'dry breadcrumbs', 'dry...  \n21785   ['unsalted butter', 'onion', 'flour', 'milk', ...  \n23559   ['potatoes', 'butter', 'flour', 'milk', 'salt'...  \n28764   ['ground beef', 'italian breadcrumbs', 'mild s...  \n31158   ['elbow macaroni', 'chicken breasts', 'low-fat...  \n31989   [\"wyler's chicken bouillon cubes\", 'water', 'r...  \n33802   ['potatoes', 'oregano', 'thyme', 'paprika', 'c...  \n40857   ['squash', 'bacon', 'onion', 'breadcrumbs', 'c...  \n45081   ['boneless skinless chicken breasts', 'pasta s...  \n60718   ['flour', 'sugar', 'baking powder', 'baking so...  \n65338   ['lean stewing beef', 'oil', 'condensed golden...  \n65678   ['flour', 'baking powder', 'butter', 'semiswee...  \n70732   ['fresh broccoli florets', 'butter', 'flour', ...  \n73721   ['boneless beef chuck roast', 'vegetable oil',...  \n96667   ['potatoes', 'garlic cloves', 'olive oil', 'wa...  \n98399   ['cauliflower', 'butter', 'seasoning salt', 'p...  \n104405  ['butter', 'eggs', 'sugar', 'milk', 'water', '...  \n115997  ['cabbage', 'eggs', 'onions', 'garlic cloves',...  \n117944  ['all-purpose flour', 'sugar', 'milk', 'vanill...  \n118135  ['olive oil', 'onion', 'dried oregano', 'garli...  \n118247  ['prime rib roast', 'garlic cloves', 'fresh gr...  \n120852  ['boneless leg of lamb', 'fresh lemon juice', ...  \n128716  ['turkey wings', 'onions', 'water', 'chicken b...  \n132364  ['pineapple slices', 'pecan halves', 'all-purp...  \n136914  ['lean ground beef', 'extra virgin olive oil',...  \n141567  ['ground beef', 'ground pork', 'onion', 'diced...  \n145841  ['saltine crackers', 'butter', 'brown sugar', ...  \n150392  ['warm water', 'fast rising yeast', 'sea salt'...  \n158366     ['long grain rice', 'water', 'butter', 'salt']  \n159071  ['all-purpose flour', 'salt', 'ground black pe...  \n173448  ['rack of baby-back pork ribs', 'brown sugar',...  \n175222  ['brussels sprouts', 'olive oil', 'kosher salt...  \n184973  ['butter', 'unsweetened cocoa powder', 'heavy ...  \n189313  ['lean stewing beef', 'cream of mushroom soup'...  \n208120  ['cooked white rice', 'sesame oil', 'celery', ...  \n213826  ['beef roast', 'brown gravy mix', 'dried itali...  \n217918  ['ground turkey', 'salt', 'sage', 'fennel seed...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>749</th>\n      <td>1 pan fudge cake</td>\n      <td>['sugar', 'cocoa', 'baking soda', 'flour', 'sa...</td>\n    </tr>\n    <tr>\n      <th>20502</th>\n      <td>beef patties in onion gravy</td>\n      <td>['ground beef', 'egg', 'dry breadcrumbs', 'dry...</td>\n    </tr>\n    <tr>\n      <th>21785</th>\n      <td>berghoff s creamed spinach</td>\n      <td>['unsalted butter', 'onion', 'flour', 'milk', ...</td>\n    </tr>\n    <tr>\n      <th>23559</th>\n      <td>bill knapp s au gratin potatoes</td>\n      <td>['potatoes', 'butter', 'flour', 'milk', 'salt'...</td>\n    </tr>\n    <tr>\n      <th>28764</th>\n      <td>bri s cheddar meatloaf</td>\n      <td>['ground beef', 'italian breadcrumbs', 'mild s...</td>\n    </tr>\n    <tr>\n      <th>31158</th>\n      <td>buffalo chicken mac n cheese</td>\n      <td>['elbow macaroni', 'chicken breasts', 'low-fat...</td>\n    </tr>\n    <tr>\n      <th>31989</th>\n      <td>buttered egg noodles  best ever</td>\n      <td>[\"wyler's chicken bouillon cubes\", 'water', 'r...</td>\n    </tr>\n    <tr>\n      <th>33802</th>\n      <td>cajun style oven fries</td>\n      <td>['potatoes', 'oregano', 'thyme', 'paprika', 'c...</td>\n    </tr>\n    <tr>\n      <th>40857</th>\n      <td>cheesy stuffed summer squash</td>\n      <td>['squash', 'bacon', 'onion', 'breadcrumbs', 'c...</td>\n    </tr>\n    <tr>\n      <th>45081</th>\n      <td>chicken parmesan foil packets</td>\n      <td>['boneless skinless chicken breasts', 'pasta s...</td>\n    </tr>\n    <tr>\n      <th>60718</th>\n      <td>cranberry orange muffins</td>\n      <td>['flour', 'sugar', 'baking powder', 'baking so...</td>\n    </tr>\n    <tr>\n      <th>65338</th>\n      <td>crock pot beef burgundy stew</td>\n      <td>['lean stewing beef', 'oil', 'condensed golden...</td>\n    </tr>\n    <tr>\n      <th>65678</th>\n      <td>crock pot chocolate mud cake</td>\n      <td>['flour', 'baking powder', 'butter', 'semiswee...</td>\n    </tr>\n    <tr>\n      <th>70732</th>\n      <td>delicious blue cheese broccoli casserole</td>\n      <td>['fresh broccoli florets', 'butter', 'flour', ...</td>\n    </tr>\n    <tr>\n      <th>73721</th>\n      <td>drunken garlic crock pot roast</td>\n      <td>['boneless beef chuck roast', 'vegetable oil',...</td>\n    </tr>\n    <tr>\n      <th>96667</th>\n      <td>greek potatoes  oven roasted and delicious</td>\n      <td>['potatoes', 'garlic cloves', 'olive oil', 'wa...</td>\n    </tr>\n    <tr>\n      <th>98399</th>\n      <td>grilled cauliflower</td>\n      <td>['cauliflower', 'butter', 'seasoning salt', 'p...</td>\n    </tr>\n    <tr>\n      <th>104405</th>\n      <td>heavenly chocolate raspberry bundt cake</td>\n      <td>['butter', 'eggs', 'sugar', 'milk', 'water', '...</td>\n    </tr>\n    <tr>\n      <th>115997</th>\n      <td>just like tony packos cabbage rolls crock pot ...</td>\n      <td>['cabbage', 'eggs', 'onions', 'garlic cloves',...</td>\n    </tr>\n    <tr>\n      <th>117944</th>\n      <td>kittencal s 5 minute cinnamon flop brunch cake</td>\n      <td>['all-purpose flour', 'sugar', 'milk', 'vanill...</td>\n    </tr>\n    <tr>\n      <th>118135</th>\n      <td>kittencal s greek lemony rice with feta</td>\n      <td>['olive oil', 'onion', 'dried oregano', 'garli...</td>\n    </tr>\n    <tr>\n      <th>118247</th>\n      <td>kittencal s perfect prime rib roast beef</td>\n      <td>['prime rib roast', 'garlic cloves', 'fresh gr...</td>\n    </tr>\n    <tr>\n      <th>120852</th>\n      <td>leg of lamb boneless greek style</td>\n      <td>['boneless leg of lamb', 'fresh lemon juice', ...</td>\n    </tr>\n    <tr>\n      <th>128716</th>\n      <td>make ahead turkey gravy</td>\n      <td>['turkey wings', 'onions', 'water', 'chicken b...</td>\n    </tr>\n    <tr>\n      <th>132364</th>\n      <td>mean chef s pineapple upside down cake</td>\n      <td>['pineapple slices', 'pecan halves', 'all-purp...</td>\n    </tr>\n    <tr>\n      <th>136914</th>\n      <td>mititei  small ground beef sausages</td>\n      <td>['lean ground beef', 'extra virgin olive oil',...</td>\n    </tr>\n    <tr>\n      <th>141567</th>\n      <td>my crock pot spaghetti sauce</td>\n      <td>['ground beef', 'ground pork', 'onion', 'diced...</td>\n    </tr>\n    <tr>\n      <th>145841</th>\n      <td>nutty soda cracker candy</td>\n      <td>['saltine crackers', 'butter', 'brown sugar', ...</td>\n    </tr>\n    <tr>\n      <th>150392</th>\n      <td>our daily bread in a crock   weekly make and b...</td>\n      <td>['warm water', 'fast rising yeast', 'sea salt'...</td>\n    </tr>\n    <tr>\n      <th>158366</th>\n      <td>perfect microwave rice</td>\n      <td>['long grain rice', 'water', 'butter', 'salt']</td>\n    </tr>\n    <tr>\n      <th>159071</th>\n      <td>pfeffernusse  german pepper nut cookies</td>\n      <td>['all-purpose flour', 'salt', 'ground black pe...</td>\n    </tr>\n    <tr>\n      <th>173448</th>\n      <td>ribs my way</td>\n      <td>['rack of baby-back pork ribs', 'brown sugar',...</td>\n    </tr>\n    <tr>\n      <th>175222</th>\n      <td>roasted brussels sprouts</td>\n      <td>['brussels sprouts', 'olive oil', 'kosher salt...</td>\n    </tr>\n    <tr>\n      <th>184973</th>\n      <td>shiny chocolate glaze</td>\n      <td>['butter', 'unsweetened cocoa powder', 'heavy ...</td>\n    </tr>\n    <tr>\n      <th>189313</th>\n      <td>slow cooker beef tips and noodles</td>\n      <td>['lean stewing beef', 'cream of mushroom soup'...</td>\n    </tr>\n    <tr>\n      <th>208120</th>\n      <td>take out fried rice</td>\n      <td>['cooked white rice', 'sesame oil', 'celery', ...</td>\n    </tr>\n    <tr>\n      <th>213826</th>\n      <td>to die for crock pot roast</td>\n      <td>['beef roast', 'brown gravy mix', 'dried itali...</td>\n    </tr>\n    <tr>\n      <th>217918</th>\n      <td>turkey breakfast sausage patties</td>\n      <td>['ground turkey', 'salt', 'sage', 'fennel seed...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                                     name  \\\n16140                                 banana banana bread   \n22388    best ever banana cake with cream cheese frosting   \n23514                   big thicket chicken and dumplings   \n67988                           cucumber sandwich filling   \n111650                      interesting crock pot chicken   \n125501           look both ways snitch and run   potatoes   \n136402                                         mini tacos   \n158260                         perfect chocolate brownies   \n167258                                    pumpkin pie dip   \n175290  roasted cauliflower   16 roasted cloves of garlic   \n\n                                              ingredients  \n16140   ['all-purpose flour', 'baking soda', 'salt', '...  \n22388   ['bananas', 'lemon juice', 'flour', 'baking so...  \n23514   ['whole chickens', 'water', 'poultry seasoning...  \n67988   ['cream cheese', 'mayonnaise', 'cucumber', 'fr...  \n111650  ['dry ranch dressing mix', 'boneless skinless ...  \n125501  ['vegetable oil', 'butter', 'seasoning salt', ...  \n136402  ['wonton wrappers', 'hamburger', 'taco seasoni...  \n158260  ['cocoa powder', 'shortening', 'sugar', 'eggs'...  \n167258  ['cream cheese', 'powdered sugar', 'pumpkin pi...  \n175290  ['cauliflower', 'garlic cloves', 'fresh rosema...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16140</th>\n      <td>banana banana bread</td>\n      <td>['all-purpose flour', 'baking soda', 'salt', '...</td>\n    </tr>\n    <tr>\n      <th>22388</th>\n      <td>best ever banana cake with cream cheese frosting</td>\n      <td>['bananas', 'lemon juice', 'flour', 'baking so...</td>\n    </tr>\n    <tr>\n      <th>23514</th>\n      <td>big thicket chicken and dumplings</td>\n      <td>['whole chickens', 'water', 'poultry seasoning...</td>\n    </tr>\n    <tr>\n      <th>67988</th>\n      <td>cucumber sandwich filling</td>\n      <td>['cream cheese', 'mayonnaise', 'cucumber', 'fr...</td>\n    </tr>\n    <tr>\n      <th>111650</th>\n      <td>interesting crock pot chicken</td>\n      <td>['dry ranch dressing mix', 'boneless skinless ...</td>\n    </tr>\n    <tr>\n      <th>125501</th>\n      <td>look both ways snitch and run   potatoes</td>\n      <td>['vegetable oil', 'butter', 'seasoning salt', ...</td>\n    </tr>\n    <tr>\n      <th>136402</th>\n      <td>mini tacos</td>\n      <td>['wonton wrappers', 'hamburger', 'taco seasoni...</td>\n    </tr>\n    <tr>\n      <th>158260</th>\n      <td>perfect chocolate brownies</td>\n      <td>['cocoa powder', 'shortening', 'sugar', 'eggs'...</td>\n    </tr>\n    <tr>\n      <th>167258</th>\n      <td>pumpkin pie dip</td>\n      <td>['cream cheese', 'powdered sugar', 'pumpkin pi...</td>\n    </tr>\n    <tr>\n      <th>175290</th>\n      <td>roasted cauliflower   16 roasted cloves of garlic</td>\n      <td>['cauliflower', 'garlic cloves', 'fresh rosema...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "# read recipe data and load pre-trained model\n",
    "df_recipes = pd.read_csv('../data/RAW_recipes.csv')\n",
    "df_recipes.drop(['minutes', 'contributor_id', 'submitted', 'tags',\n",
    "                 'nutrition', 'n_steps', 'steps', 'description', 'n_ingredients'], axis=1, inplace=True)\n",
    "data = pickle.load(open(data_path+\"data_fold0.pkl\", mode='rb'))\n",
    "model = pickle.load(open(data_path+\"model_fold0.pkl\", mode='rb'))\n",
    "predict_data = data[0]\n",
    "ratings = predict_data.rating\n",
    "idx = (predict_data.user_id, predict_data.recipe_id)\n",
    "x_train = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())), dtype=float)\n",
    "\n",
    "# get random user and make prediction\n",
    "random_user = x_train.getrow(random.randint(0, len(df.user_id.unique())))\n",
    "prediction = model.predicts(random_user)[0]\n",
    "interacted_recipes = []\n",
    "for recipe_id in random_user.indices:\n",
    "    interacted_recipes.append(recipe_dict[recipe_id])\n",
    "    prediction[recipe_id] = -100000\n",
    "\n",
    "\n",
    "top_index = (-prediction).argsort()[:10]\n",
    "recommended_recipes = []\n",
    "for recipe_id in top_index:\n",
    "    recommended_recipes.append(recipe_dict[recipe_id])\n",
    "\n",
    "# get interacted recipes and recommended recipes\n",
    "user_interactions = df_recipes[df_recipes['id'].isin(interacted_recipes)].drop('id', axis=1)\n",
    "user_recommendations = df_recipes[df_recipes['id'].isin(recommended_recipes)].drop('id', axis=1)\n",
    "\n",
    "display(user_interactions)\n",
    "display(user_recommendations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}