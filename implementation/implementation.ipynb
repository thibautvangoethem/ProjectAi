{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# project ai: Easer\n",
    "\n",
    "by Michiel Téblick and thibaut Van Goethem\n",
    "\n",
    "In this notebook we will look at the easer model proposed at https://dl.acm.org/doi/pdf/10.1145/3308558.3313710.\n",
    "\n",
    "This model will be applied to a dataset from foods.com which containes a bunch of recipes with user ratings/reactions on them.\n",
    "\n",
    "Preprocessing and fold splitting is done ahead of time.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading and preprocessing the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of interactions in the full dataset:  197073\n",
      "amount of recipes in the full dataset:  22386\n",
      "amount of users in the full dataset:  13141\n"
     ]
    },
    {
     "data": {
      "text/plain": "        index  user_id  recipe_id        date  rating  \\\n0           0   185285     127155  2005-08-11       5   \n1           1   522099     424415  2010-05-21       5   \n2           2   171790     424415  2010-05-22       4   \n3           3   537179      58758  2008-11-21       4   \n4           4   235751     116953  2005-08-28       5   \n...       ...      ...        ...         ...     ...   \n197068  38039   836288     205768  2008-11-01       4   \n197069  38040    86627      55438  2003-10-29       5   \n197070  38041     8526      34620  2003-10-26       5   \n197071  38042    41468      82303  2006-09-01       5   \n197072  38043  1122988      82303  2014-07-08       5   \n\n                                                   review  count_user  \\\n0       This recipe contained ingredients I knew I lik...         133   \n1       I really didn't expect to like this rice as mu...          61   \n2       What a wonderful aroma while cooking. Dinner g...         259   \n3       Nice recipe! I scaled this down for 2. Was nic...          57   \n4       What a great idea and recipe! It would be a re...          17   \n...                                                   ...         ...   \n197068  This recipe can it be made . on top of the sto...           8   \n197069  If everyone knew how easy and great tasting th...          17   \n197070  I've made 4 loaves of this already and it is a...          16   \n197071  WOW this was great. What I love the most is th...           9   \n197072  This was amazingly delicious!  The only change...          42   \n\n        count_item  \n0                4  \n1                6  \n2                6  \n3                3  \n4                4  \n...            ...  \n197068           5  \n197069          13  \n197070           5  \n197071          12  \n197072          12  \n\n[197073 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>recipe_id</th>\n      <th>date</th>\n      <th>rating</th>\n      <th>review</th>\n      <th>count_user</th>\n      <th>count_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>185285</td>\n      <td>127155</td>\n      <td>2005-08-11</td>\n      <td>5</td>\n      <td>This recipe contained ingredients I knew I lik...</td>\n      <td>133</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>522099</td>\n      <td>424415</td>\n      <td>2010-05-21</td>\n      <td>5</td>\n      <td>I really didn't expect to like this rice as mu...</td>\n      <td>61</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>171790</td>\n      <td>424415</td>\n      <td>2010-05-22</td>\n      <td>4</td>\n      <td>What a wonderful aroma while cooking. Dinner g...</td>\n      <td>259</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>537179</td>\n      <td>58758</td>\n      <td>2008-11-21</td>\n      <td>4</td>\n      <td>Nice recipe! I scaled this down for 2. Was nic...</td>\n      <td>57</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>235751</td>\n      <td>116953</td>\n      <td>2005-08-28</td>\n      <td>5</td>\n      <td>What a great idea and recipe! It would be a re...</td>\n      <td>17</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>197068</th>\n      <td>38039</td>\n      <td>836288</td>\n      <td>205768</td>\n      <td>2008-11-01</td>\n      <td>4</td>\n      <td>This recipe can it be made . on top of the sto...</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>197069</th>\n      <td>38040</td>\n      <td>86627</td>\n      <td>55438</td>\n      <td>2003-10-29</td>\n      <td>5</td>\n      <td>If everyone knew how easy and great tasting th...</td>\n      <td>17</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>197070</th>\n      <td>38041</td>\n      <td>8526</td>\n      <td>34620</td>\n      <td>2003-10-26</td>\n      <td>5</td>\n      <td>I've made 4 loaves of this already and it is a...</td>\n      <td>16</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>197071</th>\n      <td>38042</td>\n      <td>41468</td>\n      <td>82303</td>\n      <td>2006-09-01</td>\n      <td>5</td>\n      <td>WOW this was great. What I love the most is th...</td>\n      <td>9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>197072</th>\n      <td>38043</td>\n      <td>1122988</td>\n      <td>82303</td>\n      <td>2014-07-08</td>\n      <td>5</td>\n      <td>This was amazingly delicious!  The only change...</td>\n      <td>42</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n<p>197073 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_less_data = False # set this to true for testing purposes\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('../smallfolds/fold_0/train.csv')\n",
    "df_test = pd.read_csv('../smallfolds/fold_0/test.csv')\n",
    "df_validate = pd.read_csv('../smallfolds/fold_0/validate.csv')\n",
    "df = pd.concat([df_train, df_test, df_validate])\n",
    "\n",
    "print(\"amount of interactions in the full dataset: \",len(df))\n",
    "print(\"amount of recipes in the full dataset: \",len(df.recipe_id.unique()))\n",
    "print(\"amount of users in the full dataset: \",len(df.user_id.unique()))\n",
    "\n",
    "if use_less_data:\n",
    "    df = df[df['count_item'] >= 10]\n",
    "    print(\"amount of recipes in the smaller dataset: \",len(df.recipe_id.unique()))\n",
    "    print(\"amount of users in the smaller dataset: \",len(df.user_id.unique()))\n",
    "df.reset_index()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set all ratings to 1 (even negative interactions are seen as interactions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df.loc[:,'rating'] = 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rescaling the id's\n",
    "The recipes and users don't go from 0 to amount so if we were to put this in a matrix we would get empty columns and rows. This is not that handy so we reindex both the user_id and recipe_ids\n",
    "\n",
    "This is a step we must not forget when entering the data in the model, as we also need to remap our input data using the same remapping that was used here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "userSet = set(df['user_id'].to_list())\n",
    "user_transform_dict = dict(map(reversed, enumerate(userSet)))\n",
    "recipeSet = set(df['recipe_id'].to_list())\n",
    "recipe_transform_dict = dict(map(reversed, enumerate(recipeSet)))\n",
    "recipe_dict = dict(enumerate(recipeSet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "keep_nan_user = [k for k, v in user_transform_dict.items() if pd.isnull(v)]\n",
    "keep_nan_recipe = [k for k, v in recipe_transform_dict.items() if pd.isnull(v)]\n",
    "\n",
    "\n",
    "def transform_id(dataframe):\n",
    "    tochange = dataframe['user_id']\n",
    "    dataframe['user_id'] = tochange.map(user_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan_user)))\n",
    "\n",
    "    tochange = dataframe['recipe_id']\n",
    "    dataframe['recipe_id'] = tochange.map(recipe_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan_recipe)))\n",
    "    return dataframe\n",
    "\n",
    "def open_csv(filename, use_less_data=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    if use_less_data:\n",
    "        df = df[df['count_item'] >= 10]\n",
    "    df = transform_id(df)\n",
    "    df.loc[:,'rating'] = 1\n",
    "    df.drop('review', axis=1, inplace=True)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creation of the folds\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "k = 10\n",
    "folds = list()\n",
    "for directory in [\"../smallfolds/fold_%d\" % i for i in range(k)]:\n",
    "    folds.append(( directory + \"/train.csv\", directory + \"/validate.csv\",directory + \"/test.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creation model\n",
    "Here we define the models used for the experiments. Both the easer predictor and a populaliry predictor are created. the popularity predictor is used as a baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def split_test(data_set):\n",
    "    ground_truth = data_set.sort_values('date').groupby('user_id').tail(1)\n",
    "    predict = pd.concat([data_set, ground_truth]).drop_duplicates(keep=False)\n",
    "    return predict, ground_truth\n",
    "\n",
    "def data_frame_to_matrix(dataframe):\n",
    "    ratings = dataframe.rating\n",
    "    idx = (dataframe.user_id, dataframe.recipe_id)\n",
    "    return sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())),\n",
    "                                dtype=float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class popularity:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train(self, data):\n",
    "        data = data.sort_values('count_user',ascending=False)\n",
    "        self.pop = data[data.columns[1]].to_numpy()\n",
    "    def predict(self):\n",
    "        return self.pop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class Easer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, lambda_=1250):\n",
    "        #Code here is a modified version of the code provided in the paper\n",
    "\n",
    "        G = X_train.T.dot(X_train)\n",
    "        G = G.toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        diagIndices\n",
    "        P = scipy.linalg.inv(G)\n",
    "        del G\n",
    "        div = -np.diag(P)\n",
    "        self.B = P / div\n",
    "        self.B[diagIndices] = 0\n",
    "\n",
    "\n",
    "    def predict(self, xu):\n",
    "        return xu * self.B\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "K = 10\n",
    "K2 = 10\n",
    "\n",
    "def recal_easer(model, predict_data, test_data):\n",
    "    total = len(test_data)\n",
    "\n",
    "    X_train = data_frame_to_matrix(predict_data)\n",
    "    y_pred = model.predict(X_train)\n",
    "\n",
    "    X_test = data_frame_to_matrix(test_data)\n",
    "\n",
    "    interacted_recipes = (X_train == 1).toarray()\n",
    "    y_pred[interacted_recipes] = -100000\n",
    "    idx_top_scores = (-y_pred).argsort()[:,:10]\n",
    "    dense_X_test = X_test.toarray()\n",
    "\n",
    "    correct_K = 0\n",
    "    correct_K2 = 0\n",
    "    ndcg = 0\n",
    "\n",
    "    for idx, row in enumerate(idx_top_scores):\n",
    "        for rank, index in enumerate(row):\n",
    "            if dense_X_test[idx][index] == 1:\n",
    "                if rank < K:\n",
    "                    correct_K += 1\n",
    "                if rank < K2:\n",
    "                    correct_K2 += 1\n",
    "                ndcg += 1/(math.log2(rank+2))\n",
    "\n",
    "    print(\"easer recall@%s = %s\" % (str(K), str(correct_K / total)))\n",
    "    print(\"easer recall@%s = %s\" % (str(K2), str(correct_K2 / total)))\n",
    "    print(\"easer ndcg@%s = %s\" % (100, str(ndcg / total)), end=\"\\n\\n\")\n",
    "\n",
    "    return correct_K/total, correct_K2/total, ndcg/total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## training models + evaluation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training took :  159.5821979045868 s\n",
      "training took :  160.7154998779297 s\n",
      "training took :  157.91159868240356 s\n",
      "training took :  154.6998155117035 s\n",
      "training took :  155.2664613723755 s\n",
      "training took :  159.19303345680237 s\n",
      "training took :  157.98179507255554 s\n",
      "training took :  160.0924220085144 s\n",
      "training took :  160.4871311187744 s\n",
      "training took :  154.44989609718323 s\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "mean requires at least one data point",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mStatisticsError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-11-496b92c3a5da>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     41\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"training took : \"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"s\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"mean recall@%s over 10 folds: \"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mK\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult_list_K\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"mean recall@%s over 10 folds: \"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mK2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult_list_K2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"mean ndcg@%s over 10 folds: \"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult_ndcg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"\\n\\n\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\statistics.py\u001B[0m in \u001B[0;36mmean\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    313\u001B[0m     \u001B[0mn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 315\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mStatisticsError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'mean requires at least one data point'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    316\u001B[0m     \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtotal\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_sum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    317\u001B[0m     \u001B[1;32massert\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mStatisticsError\u001B[0m: mean requires at least one data point"
     ]
    }
   ],
   "source": [
    "#Please enter the path here of where you will place the pickle files (with trailing /)\n",
    "data_path=\"D:/results_aiproject_improvement/\"\n",
    "result_list_K = list()\n",
    "result_list_K2 = list()\n",
    "result_ndcg = list()\n",
    "\n",
    "for f_idx, fold_files in enumerate(folds):\n",
    "    start = time.time()\n",
    "    train_data = open_csv(fold_files[0], True)\n",
    "    #Here we have the user item matrix\n",
    "    X_train = data_frame_to_matrix(train_data)\n",
    "\n",
    "    #train models\n",
    "\n",
    "    model_pop=popularity()\n",
    "    model_pop.train(train_data)\n",
    "    # modelpopfile = open(data_path+\"model_pop_fold\" + str(f_idx) + \".pkl\", mode='wb')\n",
    "    # pickle.dump(model_pop, modelpopfile)\n",
    "    # modelpopfile.close()\n",
    "    # del model_pop\n",
    "\n",
    "    test_data = open_csv(fold_files[1], use_less_data)\n",
    "\n",
    "    model = Easer()\n",
    "    model.train(X_train, lambda_=1250)\n",
    "    interactions, ground_truth = split_test(test_data)\n",
    "\n",
    "    recall20, recall50, ndcg = recal_easer(model, interactions, ground_truth)\n",
    "\n",
    "    result_list_K.append(recall20)\n",
    "    result_list_K2.append(recall50)\n",
    "    result_ndcg.append(ndcg)\n",
    "\n",
    "    print(\"done fold:\",str(f_idx))\n",
    "    #\n",
    "    # print(\"easer fold: %s, recall@%s = %s\" % (str(f_idx), str(K), recall20))\n",
    "    # print(\"easer fold: %s, recall@%s = %s\" % (str(f_idx), str(K2), recall50))\n",
    "    # print(\"easer fold: %s, ndcg@%s = %s\" % (str(f_idx), 100, ndcg), end=\"\\n\\n\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"training took : \", end - start, \"s\")\n",
    "\n",
    "print(\"mean recall@%s over 10 folds: \" % str(K), str(st.mean(result_list_K)))\n",
    "print(\"mean recall@%s over 10 folds: \" % str(K2), str(st.mean(result_list_K2)))\n",
    "print(\"mean ndcg@%s over 10 folds: \" % str(100), str(st.mean(result_ndcg)), end=\"\\n\\n\")\n",
    "print(\"standard deviation recall@%s over 10 folds: \" % str(K), str(st.pstdev(result_list_K)))\n",
    "print(\"standard deviation recall@%s over 10 folds: \" % str(K2), str(st.pstdev(result_list_K2)))\n",
    "print(\"standard deviation ndcg@%s over 10 folds: \" % str(100), str(st.pstdev(result_ndcg)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation results of the folds\n",
    "\n",
    "Here we use recall@20, recal@50 and ndcg@100\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#recall score for popularity\n",
    "result_list_pop_K5=list()\n",
    "result_list_pop_K10=list()\n",
    "result_list_pop_K20=list()\n",
    "result_list_pop_ndcg5=list()\n",
    "result_list_pop_ndcg10=list()\n",
    "result_list_pop_ndcg20=list()\n",
    "for i in range(k):\n",
    "    test_data = open_csv(folds[i][2], True)\n",
    "    predict_data, ground_truth = split_test(test_data)\n",
    "    model = pickle.load(open(data_path+\"model_pop_fold\"+str(i)+\".pkl\", mode='rb'))\n",
    "\n",
    "    pop=model.predict()\n",
    "    total = 0\n",
    "    correct_K5 = 0\n",
    "    correct_K10 = 0\n",
    "    correct_K20 = 0\n",
    "    ndcg5 = 0\n",
    "    ndcg10 = 0\n",
    "    ndcg20 = 0\n",
    "    for idx, interaction in ground_truth.iterrows():\n",
    "        user = interaction['user_id']\n",
    "        user_data = predict_data.loc[(predict_data['user_id'] == user)]\n",
    "        already_interacted_recipes = user_data[user_data.columns[1]].to_numpy()\n",
    "        newpop = pop[:150]\n",
    "        newpop = newpop[~np.in1d(newpop,already_interacted_recipes)]\n",
    "        newpop_K5 = newpop[:5]\n",
    "        newpop_K10 = newpop[:10]\n",
    "        newpop_K20 = newpop[:20]\n",
    "        # newpop_ndcg5 = newpop[:5]\n",
    "        # newpop_ndcg10 = newpop[:10]\n",
    "        # newpop_ndcg20 = newpop[:20]\n",
    "        recipe = interaction['recipe_id']\n",
    "        if recipe in newpop_K5:\n",
    "            correct_K5 += 1\n",
    "        if recipe in newpop_K10:\n",
    "            correct_K10 += 1\n",
    "        if recipe in newpop_K20:\n",
    "            correct_K20 += 1\n",
    "\n",
    "        if recipe in newpop_K5:\n",
    "            ndcg5 += 1/(math.log2(np.where(newpop_K5 == recipe)[0]+2))\n",
    "        if recipe in newpop_K5:\n",
    "            ndcg10 += 1/(math.log2(np.where(newpop_K10 == recipe)[0]+2))\n",
    "        if recipe in newpop_K5:\n",
    "            ndcg20 += 1/(math.log2(np.where(newpop_K20 == recipe)[0]+2))\n",
    "        total += 1\n",
    "    result_list_pop_K5.append(correct_K5 / total)\n",
    "    result_list_pop_K10.append(correct_K10 / total)\n",
    "    result_list_pop_K20.append(correct_K20 / total)\n",
    "    result_list_pop_ndcg5.append(ndcg5 / total)\n",
    "    result_list_pop_ndcg10.append(ndcg10 / total)\n",
    "    result_list_pop_ndcg20.append(ndcg20 / total)\n",
    "    print(\"popularity fold: %s, recall@5,10,20 = %s,%s,%s\" % (str(i), str(correct_K5 / total),str(correct_K10 / total),str(correct_K20 / total)))\n",
    "    print(\"popularity fold: %s, ndcg@5,10,20 = %s,%s,%s\" % (str(i),str(ndcg5 / total),str(ndcg10 / total),str(ndcg20 / total)), end=\"\\n\\n\")\n",
    "\n",
    "print(\"mean recall@5,10,20 over 10 folds: %s,%s,%s\" % (str(st.mean(result_list_pop_K5)),str(st.mean(result_list_pop_K10)),str(st.mean(result_list_pop_K20))))\n",
    "print(\"mean ndcg@5,10,20 over 10 folds: %s,%s,%s\" % (str(st.mean(result_list_pop_ndcg5)),str(st.mean(result_list_pop_ndcg10)),str(st.mean(result_list_pop_ndcg20))), end=\"\\n\\n\")\n",
    "print(\"standard deviation recall@5,10,20 over 10 folds: %s,%s,%s\" %(str(st.pstdev(result_list_pop_K5)), str(st.pstdev(result_list_pop_K10)), str(st.pstdev(result_list_pop_K20))))\n",
    "print(\"standard deviation ndcg@5,10,20 over 10 folds: %s,%s,%s\" % (str(st.pstdev(result_list_pop_ndcg5)),str(st.pstdev(result_list_pop_ndcg10)),str(st.pstdev(result_list_pop_ndcg20))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next section is a demonstration that selects a random user and makes a recommendation prediction for this user."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import random\n",
    "# # read recipe data and load pre-trained model\n",
    "# df_recipes = pd.read_csv('../data/RAW_recipes.csv')\n",
    "# df_recipes.drop(['minutes', 'contributor_id', 'submitted', 'tags',\n",
    "#                  'nutrition', 'n_steps', 'steps', 'description', 'n_ingredients'], axis=1, inplace=True)\n",
    "# data = pickle.load(open(data_path+\"data_fold0.pkl\", mode='rb'))\n",
    "# model = pickle.load(open(data_path+\"model_fold0.pkl\", mode='rb'))\n",
    "# predict_data = data[0]\n",
    "# ratings = predict_data.rating\n",
    "# idx = (predict_data.user_id, predict_data.recipe_id)\n",
    "# x_train = sparse.csc_matrix((ratings, idx), shape=(len(df.user_id.unique()), len(df.recipe_id.unique())), dtype=float)\n",
    "#\n",
    "# # get random user and make prediction\n",
    "# random_user = x_train.getrow(random.randint(0, len(df.user_id.unique())))\n",
    "# prediction = model.predict(random_user)[0]\n",
    "# interacted_recipes = []\n",
    "# for recipe_id in random_user.indices:\n",
    "#     interacted_recipes.append(recipe_dict[recipe_id])\n",
    "#     prediction[recipe_id] = -100000\n",
    "#\n",
    "#\n",
    "# top_index = (-prediction).argsort()[:10]\n",
    "# recommended_recipes = []\n",
    "# for recipe_id in top_index:\n",
    "#     recommended_recipes.append(recipe_dict[recipe_id])\n",
    "#\n",
    "# # get interacted recipes and recommended recipes\n",
    "# user_interactions = df_recipes[df_recipes['id'].isin(interacted_recipes)].drop('id', axis=1)\n",
    "# user_recommendations = df_recipes[df_recipes['id'].isin(recommended_recipes)].drop('id', axis=1)\n",
    "#\n",
    "# display(user_interactions)\n",
    "# display(user_recommendations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}