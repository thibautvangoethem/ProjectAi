{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# project ai: Easer\n",
    "\n",
    "by Michiel Téblick and thibaut Van Goethem\n",
    "\n",
    "In this notebook we will test the hypothesis that is easer not good at predicting the long tail\n",
    "Preprocessing and fold splitting is done ahead of time.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading and preprocessing the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of interactions in the full dataset:  733951\n",
      "amount of recipes in the full dataset:  80511\n",
      "amount of users in the full dataset:  32635\n",
      "amount of recipes in the smaller dataset:  9030\n",
      "amount of users in the smaller dataset:  31075\n"
     ]
    },
    {
     "data": {
      "text/plain": "         index  user_id  recipe_id        date  rating  \\\n0            0    56680      79222  2006-11-11       1   \n1            1   827374      79222  2010-11-29       1   \n2           21    89831      33096  2004-03-15       1   \n3           22   231054      33096  2007-10-25       1   \n4           23   470894      33096  2010-04-27       1   \n...        ...      ...        ...         ...     ...   \n347051  151892   315805      55438  2011-12-29       1   \n347052  151900  1423741      39902  2012-07-25       1   \n347053  151907   422893     196735  2009-01-02       1   \n347054  151908    96177     196735  2009-01-12       1   \n347055  151909   573325     196735  2010-09-08       1   \n\n                                                   review  count_user  \\\n0       Oh, This was wonderful!  Had a soup and salad ...         174   \n1       We made this last night and really enjoyed it....          10   \n2       Merlot...this is the second time that I made y...        2572   \n3       I love this -- and idea behind it.  I'm sure y...         266   \n4       so simple to put together and very refreshing....          13   \n...                                                   ...         ...   \n347051  I had a ham bone leftover from Christmas dinne...          46   \n347052  I switched out the American Cheese for Sharp C...           7   \n347053  Yum, Yum, I love potatoes with Rosemary & this...        1130   \n347054  We just loved these tatters. Quick easy and ve...         563   \n347055  What a great, healthy, easy and yummy recipe!<...         880   \n\n        count_item  \n0               18  \n1               18  \n2               27  \n3               27  \n4               27  \n...            ...  \n347051          17  \n347052          15  \n347053          17  \n347054          17  \n347055          17  \n\n[347056 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>recipe_id</th>\n      <th>date</th>\n      <th>rating</th>\n      <th>review</th>\n      <th>count_user</th>\n      <th>count_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>56680</td>\n      <td>79222</td>\n      <td>2006-11-11</td>\n      <td>1</td>\n      <td>Oh, This was wonderful!  Had a soup and salad ...</td>\n      <td>174</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>827374</td>\n      <td>79222</td>\n      <td>2010-11-29</td>\n      <td>1</td>\n      <td>We made this last night and really enjoyed it....</td>\n      <td>10</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>89831</td>\n      <td>33096</td>\n      <td>2004-03-15</td>\n      <td>1</td>\n      <td>Merlot...this is the second time that I made y...</td>\n      <td>2572</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22</td>\n      <td>231054</td>\n      <td>33096</td>\n      <td>2007-10-25</td>\n      <td>1</td>\n      <td>I love this -- and idea behind it.  I'm sure y...</td>\n      <td>266</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>470894</td>\n      <td>33096</td>\n      <td>2010-04-27</td>\n      <td>1</td>\n      <td>so simple to put together and very refreshing....</td>\n      <td>13</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>347051</th>\n      <td>151892</td>\n      <td>315805</td>\n      <td>55438</td>\n      <td>2011-12-29</td>\n      <td>1</td>\n      <td>I had a ham bone leftover from Christmas dinne...</td>\n      <td>46</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>347052</th>\n      <td>151900</td>\n      <td>1423741</td>\n      <td>39902</td>\n      <td>2012-07-25</td>\n      <td>1</td>\n      <td>I switched out the American Cheese for Sharp C...</td>\n      <td>7</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>347053</th>\n      <td>151907</td>\n      <td>422893</td>\n      <td>196735</td>\n      <td>2009-01-02</td>\n      <td>1</td>\n      <td>Yum, Yum, I love potatoes with Rosemary &amp; this...</td>\n      <td>1130</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>347054</th>\n      <td>151908</td>\n      <td>96177</td>\n      <td>196735</td>\n      <td>2009-01-12</td>\n      <td>1</td>\n      <td>We just loved these tatters. Quick easy and ve...</td>\n      <td>563</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>347055</th>\n      <td>151909</td>\n      <td>573325</td>\n      <td>196735</td>\n      <td>2010-09-08</td>\n      <td>1</td>\n      <td>What a great, healthy, easy and yummy recipe!&lt;...</td>\n      <td>880</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n<p>347056 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_less_data = True\n",
    "\n",
    "df_train = pd.read_csv('../folds/fold_0/train.csv')\n",
    "df_test = pd.read_csv('../folds/fold_0/test.csv')\n",
    "df_validate = pd.read_csv('../folds/fold_0/validate.csv')\n",
    "full_df = pd.concat([df_train, df_test, df_validate])\n",
    "full_df.reset_index()\n",
    "full_df.loc[:, 'rating'] = 1\n",
    "df=full_df\n",
    "\n",
    "print(\"amount of interactions in the full dataset: \", len(df))\n",
    "print(\"amount of recipes in the full dataset: \", len(df.recipe_id.unique()))\n",
    "print(\"amount of users in the full dataset: \", len(df.user_id.unique()))\n",
    "\n",
    "if use_less_data:\n",
    "    lesser_cuttoff=15\n",
    "    df = df[df['count_item'] >= lesser_cuttoff]\n",
    "    # df_smaller.reset_index()\n",
    "    print(\"amount of recipes in the smaller dataset: \", len(df.recipe_id.unique()))\n",
    "    print(\"amount of users in the smaller dataset: \", len(df.user_id.unique()))\n",
    "df.reset_index()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set all ratings to 1 (even negative interactions are seen as interactions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiba\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "df.loc[:, 'rating'] = 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rescaling the id's\n",
    "The recipes and users don't go from 0 to amount so if we were to put this in a matrix we would get empty columns and rows. This is not that handy so we reindex both the user_id and recipe_ids\n",
    "\n",
    "This is a step we must not forget when entering the data in the model, as we also need to remap our input data using the same remapping that was used here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "userSet = set(df['user_id'].to_list())\n",
    "user_transform_dict = dict(map(reversed, enumerate(userSet)))\n",
    "recipeSet = set(df['recipe_id'].to_list())\n",
    "recipe_transform_dict = dict(map(reversed, enumerate(recipeSet)))\n",
    "recipe_dict = dict(enumerate(recipeSet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "reverse_recipes = {v: k for k, v in recipe_transform_dict.items()}\n",
    "reverse_users = {v: k for k, v in user_transform_dict.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "keep_nan_user = [k for k, v in user_transform_dict.items() if pd.isnull(v)]\n",
    "keep_nan_recipe = [k for k, v in recipe_transform_dict.items() if pd.isnull(v)]\n",
    "\n",
    "\n",
    "def transform_id(dataframe):\n",
    "    userSet = set(dataframe['user_id'].to_list())\n",
    "    user_transform_dict = dict(map(reversed, enumerate(userSet)))\n",
    "    tochange = dataframe['user_id']\n",
    "    dataframe['user_id'] = tochange.map(user_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan_user)))\n",
    "\n",
    "    tochange = dataframe['recipe_id']\n",
    "    dataframe['recipe_id'] = tochange.map(recipe_transform_dict).fillna(tochange.mask(tochange.isin(keep_nan_recipe)))\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def open_csv(filename, use_less_data=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    if use_less_data:\n",
    "        df = df[df['count_item'] >= lesser_cuttoff]\n",
    "    df = transform_id(df)\n",
    "    df.loc[:, 'rating'] = 1\n",
    "    df.drop('review', axis=1, inplace=True)\n",
    "    df['count_user'] = df.groupby(['user_id'])['user_id'].transform('size')\n",
    "    # df = df.drop(df[(df['count_user'] <= 2)].index)\n",
    "    df['count_item'] = df.groupby(['recipe_id'])['recipe_id'].transform('size')\n",
    "    # df = df.drop(df[(df['count_item'] <= 2)].index)\n",
    "    #df.drop('date', axis=1, inplace=True)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creation of the folds\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "k = 10\n",
    "folds = list()\n",
    "for directory in [\"../folds/fold_%d\" % i for i in range(k)]:\n",
    "    folds.append((directory + \"/train.csv\", directory + \"/validate.csv\", directory + \"/test.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creation model\n",
    "Here we define the models used for the experiments. Both the easer predictor and a populaliry predictor are created. the popularity predictor is used as a baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def split_test(data_set):\n",
    "    ground_truth = data_set.sort_values('date').groupby('user_id').tail(1)\n",
    "    predict = pd.concat([data_set, ground_truth]).drop_duplicates(keep=False)\n",
    "    predict=predict[predict.recipe_id.isin(reverse_recipes)==True]\n",
    "    predict.reset_index()\n",
    "    return predict, ground_truth\n",
    "\n",
    "\n",
    "def data_frame_to_matrix(dataframe):\n",
    "    ratings = dataframe.rating\n",
    "    idx = (dataframe.user_id, dataframe.recipe_id)\n",
    "    return sparse.csc_matrix((ratings, idx), shape=(dataframe.user_id.max()+1, len(df.recipe_id.unique())),\n",
    "                             dtype=np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class popularity:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, data):\n",
    "        data = data.sort_values('count_item', ascending=False)\n",
    "        self.pop = data[data.columns[1]].unique()\n",
    "\n",
    "    def predict(self):\n",
    "        return self.pop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Easer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X_train, lambda_=1250):\n",
    "        #Code here is a modified version of the code provided in the paper\n",
    "\n",
    "        G = X_train.T.dot(X_train)\n",
    "        G = G.toarray()\n",
    "        diagIndices = np.diag_indices(G.shape[0])\n",
    "        G[diagIndices] += lambda_\n",
    "        P = scipy.linalg.inv(G)\n",
    "        del G\n",
    "        div = -np.diag(P)\n",
    "        self.B = P / div\n",
    "        self.B[diagIndices] = 0\n",
    "\n",
    "    def predict(self, xu):\n",
    "        return xu * self.B\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "K = 5\n",
    "K2 = 10\n",
    "K3 = 20\n",
    "\n",
    "\n",
    "def recal_easer(model, predict_data, test_data):\n",
    "    total = len(test_data)\n",
    "    print(total)\n",
    "    X_train = data_frame_to_matrix(predict_data)\n",
    "    y_pred = model.predict(X_train)\n",
    "    print(len(test_data[test_data.recipe_id.isin(reverse_recipes)==False]))\n",
    "    test_data=test_data[test_data.recipe_id.isin(reverse_recipes)==True]\n",
    "    X_test = data_frame_to_matrix(test_data)\n",
    "\n",
    "    interacted_recipes = (X_train == 1).toarray()\n",
    "    y_pred[interacted_recipes] = -100000\n",
    "    idx_top_scores = (-y_pred).argsort()[:, :100]\n",
    "    dense_X_test = X_test.toarray()\n",
    "\n",
    "    correct_K = 0\n",
    "    correct_K2 = 0\n",
    "    correct_K3 = 0\n",
    "    ndcg_K = 0\n",
    "    ndcg_K2 = 0\n",
    "    ndcg_K3 = 0\n",
    "\n",
    "    for idx, row in enumerate(idx_top_scores):\n",
    "        if(idx>=len(dense_X_test)):continue\n",
    "        for rank, index in enumerate(row):\n",
    "            if dense_X_test[idx][index] == 1:\n",
    "                if rank < K:\n",
    "                    correct_K += 1\n",
    "                    ndcg_K += 1/(math.log2(rank+2))\n",
    "                if rank < K2:\n",
    "                    correct_K2 += 1\n",
    "                    ndcg_K2 += 1/(math.log2(rank+2))\n",
    "                if rank < K3:\n",
    "                    correct_K3 += 1\n",
    "                    ndcg_K3 += 1/(math.log2(rank+2))\n",
    "\n",
    "\n",
    "    print(\"easer recall@5,10,20 = %s,%s,%s\" % (str(correct_K / total),str(correct_K2 / total),str(correct_K3 / total)))\n",
    "    print(\"easer ndcg@5,10,20 = %s,%s,%s\" % (str(ndcg_K / total),str(ndcg_K2 / total),str(ndcg_K3 / total)), end=\"\\n\\n\")\n",
    "\n",
    "    return correct_K/total, correct_K2/total,correct_K3/total, ndcg_K/total,ndcg_K2/total,ndcg_K3/total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## training models + evaluation\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242967\n",
      "6528\n",
      "2731\n",
      "easer recall@5,10,20 = 0.013786764705882353,0.020833333333333332,0.03262867647058824\n",
      "easer ndcg@5,10,20 = 0.009151513766222055,0.011409928793355017,0.014396394451212014\n",
      "\n",
      "training took :  20.78832244873047 s\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "mean requires at least one data point",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mStatisticsError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-5381b30ffce6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"mean recall@%s over 10 folds: \"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mK\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult_list_K\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"mean recall@%s over 10 folds: \"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mK2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult_list_K2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"mean ndcg@%s over 10 folds: \"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult_ndcg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"\\n\\n\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\statistics.py\u001B[0m in \u001B[0;36mmean\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    313\u001B[0m     \u001B[0mn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 315\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mStatisticsError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'mean requires at least one data point'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    316\u001B[0m     \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtotal\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_sum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    317\u001B[0m     \u001B[1;32massert\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mStatisticsError\u001B[0m: mean requires at least one data point"
     ]
    }
   ],
   "source": [
    "#Please enter the path here of where you will place the pickle files (with trailing /)\n",
    "data_path = \"D:/results_aiproject_improvement/\"\n",
    "result_list_K = list()\n",
    "result_list_K2 = list()\n",
    "result_ndcg = list()\n",
    "\n",
    "for f_idx, fold_files in enumerate(folds):\n",
    "    start = time.time()\n",
    "    train_data = open_csv(fold_files[0], True)\n",
    "    print(len(train_data))\n",
    "    #Here we have the user item matrix\n",
    "    X_train = data_frame_to_matrix(train_data)\n",
    "\n",
    "    #train models\n",
    "\n",
    "    test_data = open_csv(fold_files[1], False)\n",
    "\n",
    "    model = Easer()\n",
    "    model.train(X_train, lambda_=1250)\n",
    "    interactions, ground_truth = split_test(test_data)\n",
    "\n",
    "    recal_easer(model, interactions, ground_truth)\n",
    "\n",
    "    # result_list_K.append(recall20)\n",
    "    # result_list_K2.append(recall50)\n",
    "    # result_ndcg.append(ndcg)\n",
    "    #\n",
    "    # print(\"done fold:\",str(f_idx))\n",
    "    #\n",
    "    # print(\"easer fold: %s, recall@%s = %s\" % (str(f_idx), str(K), recall20))\n",
    "    # print(\"easer fold: %s, recall@%s = %s\" % (str(f_idx), str(K2), recall50))\n",
    "    # print(\"easer fold: %s, ndcg@%s = %s\" % (str(f_idx), 100, ndcg), end=\"\\n\\n\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"training took : \", end - start, \"s\")\n",
    "    break\n",
    "\n",
    "print(\"mean recall@%s over 10 folds: \" % str(K), str(st.mean(result_list_K)))\n",
    "print(\"mean recall@%s over 10 folds: \" % str(K2), str(st.mean(result_list_K2)))\n",
    "print(\"mean ndcg@%s over 10 folds: \" % str(100), str(st.mean(result_ndcg)), end=\"\\n\\n\")\n",
    "print(\"standard deviation recall@%s over 10 folds: \" % str(K), str(st.pstdev(result_list_K)))\n",
    "print(\"standard deviation recall@%s over 10 folds: \" % str(K2), str(st.pstdev(result_list_K2)))\n",
    "print(\"standard deviation ndcg@%s over 10 folds: \" % str(100), str(st.pstdev(result_ndcg)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = open_csv(folds[0][1], False)\n",
    "interactions, ground_truth = split_test(test_data)\n",
    "recal_easer(model, interactions, ground_truth)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(recipe_transform_dict[67256])\n",
    "for i in recipe_transform_dict:\n",
    "    if (recipe_transform_dict[i] in [10785, 35451, 15749, 13017, 28357, 22286, 8752, 10150, 27639, 32783]):\n",
    "        print(i)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}